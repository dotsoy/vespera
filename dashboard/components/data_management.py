"""
æ•°æ®ç®¡ç†ç»„ä»¶
"""
import streamlit as st
import pandas as pd
import plotly.graph_objects as go
import plotly.express as px
from datetime import datetime, timedelta
import asyncio
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from src.utils.logger import get_logger

logger = get_logger("data_management")

# æ•°æ®åº“è¿æ¥
try:
    from src.utils.database import get_db_manager
    DB_AVAILABLE = True
except ImportError as e:
    logger.warning(f"æ•°æ®åº“æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
    DB_AVAILABLE = False

# æ•°æ®æºå®¢æˆ·ç«¯
try:
    from src.data_sources.tushare_client import TushareClient
    TUSHARE_AVAILABLE = True
except ImportError as e:
    logger.warning(f"Tushareå®¢æˆ·ç«¯å¯¼å…¥å¤±è´¥: {e}")
    TUSHARE_AVAILABLE = False

try:
    from src.data_sources.alltick_client import AllTickClient
    ALLTICK_AVAILABLE = True
except ImportError as e:
    logger.warning(f"AllTickå®¢æˆ·ç«¯å¯¼å…¥å¤±è´¥: {e}")
    ALLTICK_AVAILABLE = False

try:
    from src.data_sources.alpha_vantage_client import AlphaVantageClient
    ALPHA_VANTAGE_AVAILABLE = True
except ImportError as e:
    logger.warning(f"Alpha Vantageå®¢æˆ·ç«¯å¯¼å…¥å¤±è´¥: {e}")
    ALPHA_VANTAGE_AVAILABLE = False

def execute_real_data_update(data_source, update_type, target_date, update_scope, selected_stocks):
    """æ‰§è¡ŒçœŸå®çš„æ•°æ®æ›´æ–°"""

    # åˆ›å»ºè¿›åº¦æ˜¾ç¤ºåŒºåŸŸ
    progress_container = st.container()
    log_container = st.container()

    with progress_container:
        st.info(f"ğŸ”„ æ­£åœ¨ä» {data_source} æ›´æ–°æ•°æ®...")

        # æ€»è¿›åº¦æ¡
        total_progress = st.progress(0)
        total_status = st.empty()

        # è¯¦ç»†è¿›åº¦
        detail_progress = st.progress(0)
        detail_status = st.empty()

    with log_container:
        st.subheader("ğŸ“‹ æ›´æ–°æ—¥å¿—")
        log_area = st.empty()

    logs = []

    try:
        # 1. åˆå§‹åŒ–æ•°æ®æºå®¢æˆ·ç«¯
        total_progress.progress(5)
        total_status.text("åˆå§‹åŒ–æ•°æ®æºè¿æ¥...")
        logs.append(f"[{datetime.now().strftime('%H:%M:%S')}] å°è¯•è¿æ¥ {data_source}...")
        log_area.text_area("", value="\n".join(logs), height=300, disabled=True)

        client = None

        # å°è¯•ä¸åŒçš„æ•°æ®æº
        if data_source.startswith("Tushare"):
            if not TUSHARE_AVAILABLE:
                logs.append(f"[{datetime.now().strftime('%H:%M:%S')}] âŒ Tushareæ¨¡å—æœªå®‰è£…æˆ–å¯¼å…¥å¤±è´¥")
                st.error("âŒ Tushareæ•°æ®æºä¸å¯ç”¨ï¼šæ¨¡å—æœªå®‰è£…æˆ–å¯¼å…¥å¤±è´¥")
                return

            try:
                client = TushareClient()
                logs.append(f"[{datetime.now().strftime('%H:%M:%S')}] âœ… Tushareå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")

                # æµ‹è¯•APIæƒé™
                test_df = client.get_stock_basic()
                if test_df.empty:
                    logs.append(f"[{datetime.now().strftime('%H:%M:%S')}] âŒ Tushare APIæƒé™ä¸è¶³æˆ–æ— æ•°æ®")
                    st.error("âŒ Tushareæ•°æ®æºå¤±è´¥ï¼šAPIæƒé™ä¸è¶³ï¼Œè¯·æ£€æŸ¥Tokenæƒé™æˆ–å‡çº§è´¦æˆ·")
                    return
                else:
                    logs.append(f"[{datetime.now().strftime('%H:%M:%S')}] âœ… Tushare APIæƒé™éªŒè¯æˆåŠŸ")

            except Exception as e:
                error_msg = str(e)
                if "æƒé™" in error_msg or "permission" in error_msg.lower():
                    logs.append(f"[{datetime.now().strftime('%H:%M:%S')}] âŒ Tushare APIæƒé™ä¸è¶³: {error_msg}")
                    st.error(f"âŒ Tushareæ•°æ®æºå¤±è´¥ï¼šAPIæƒé™ä¸è¶³ - {error_msg}")
                elif "token" in error_msg.lower():
                    logs.append(f"[{datetime.now().strftime('%H:%M:%S')}] âŒ Tushare Tokené…ç½®é”™è¯¯: {error_msg}")
                    st.error(f"âŒ Tushareæ•°æ®æºå¤±è´¥ï¼šTokené…ç½®é”™è¯¯ - {error_msg}")
                else:
                    logs.append(f"[{datetime.now().strftime('%H:%M:%S')}] âŒ Tushareè¿æ¥å¤±è´¥: {error_msg}")
                    st.error(f"âŒ Tushareæ•°æ®æºå¤±è´¥ï¼šè¿æ¥é”™è¯¯ - {error_msg}")
                return

        elif data_source == "AllTick":
            if not ALLTICK_AVAILABLE:
                logs.append(f"[{datetime.now().strftime('%H:%M:%S')}] âŒ AllTickæ¨¡å—æœªå®‰è£…æˆ–å¯¼å…¥å¤±è´¥")
                st.error("âŒ AllTickæ•°æ®æºä¸å¯ç”¨ï¼šæ¨¡å—æœªå®‰è£…æˆ–å¯¼å…¥å¤±è´¥")
                return

            try:
                client = AllTickClient()
                logs.append(f"[{datetime.now().strftime('%H:%M:%S')}] âœ… AllTickå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")

                # æµ‹è¯•è¿æ¥
                test_result = client.test_connection()
                if not test_result:
                    logs.append(f"[{datetime.now().strftime('%H:%M:%S')}] âŒ AllTickè¿æ¥æµ‹è¯•å¤±è´¥")
                    st.error("âŒ AllTickæ•°æ®æºå¤±è´¥ï¼šè¿æ¥æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥API Token")
                    return
                else:
                    logs.append(f"[{datetime.now().strftime('%H:%M:%S')}] âœ… AllTickè¿æ¥æµ‹è¯•æˆåŠŸ")

            except Exception as e:
                error_msg = str(e)
                if "token" in error_msg.lower() or "key" in error_msg.lower():
                    logs.append(f"[{datetime.now().strftime('%H:%M:%S')}] âŒ AllTick Tokené…ç½®é”™è¯¯: {error_msg}")
                    st.error(f"âŒ AllTickæ•°æ®æºå¤±è´¥ï¼šTokené…ç½®é”™è¯¯ - {error_msg}")
                else:
                    logs.append(f"[{datetime.now().strftime('%H:%M:%S')}] âŒ AllTickè¿æ¥å¤±è´¥: {error_msg}")
                    st.error(f"âŒ AllTickæ•°æ®æºå¤±è´¥ï¼šè¿æ¥é”™è¯¯ - {error_msg}")
                return

        elif data_source == "Alpha Vantage":
            if not ALPHA_VANTAGE_AVAILABLE:
                logs.append(f"[{datetime.now().strftime('%H:%M:%S')}] âŒ Alpha Vantageæ¨¡å—æœªå®‰è£…æˆ–å¯¼å…¥å¤±è´¥")
                st.error("âŒ Alpha Vantageæ•°æ®æºä¸å¯ç”¨ï¼šæ¨¡å—æœªå®‰è£…æˆ–å¯¼å…¥å¤±è´¥")
                return

            try:
                client = AlphaVantageClient()
                logs.append(f"[{datetime.now().strftime('%H:%M:%S')}] âœ… Alpha Vantageå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")

                # æµ‹è¯•è¿æ¥
                test_result = client.test_connection()
                if not test_result:
                    logs.append(f"[{datetime.now().strftime('%H:%M:%S')}] âŒ Alpha Vantageè¿æ¥æµ‹è¯•å¤±è´¥")
                    st.error("âŒ Alpha Vantageæ•°æ®æºå¤±è´¥ï¼šè¿æ¥æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥API Key")
                    return
                else:
                    logs.append(f"[{datetime.now().strftime('%H:%M:%S')}] âœ… Alpha Vantageè¿æ¥æµ‹è¯•æˆåŠŸ")

            except Exception as e:
                error_msg = str(e)
                if "api" in error_msg.lower() or "key" in error_msg.lower():
                    logs.append(f"[{datetime.now().strftime('%H:%M:%S')}] âŒ Alpha Vantage API Keyé…ç½®é”™è¯¯: {error_msg}")
                    st.error(f"âŒ Alpha Vantageæ•°æ®æºå¤±è´¥ï¼šAPI Keyé…ç½®é”™è¯¯ - {error_msg}")
                else:
                    logs.append(f"[{datetime.now().strftime('%H:%M:%S')}] âŒ Alpha Vantageè¿æ¥å¤±è´¥: {error_msg}")
                    st.error(f"âŒ Alpha Vantageæ•°æ®æºå¤±è´¥ï¼šè¿æ¥é”™è¯¯ - {error_msg}")
                return
        else:
            logs.append(f"[{datetime.now().strftime('%H:%M:%S')}] âŒ ä¸æ”¯æŒçš„æ•°æ®æº: {data_source}")
            st.error(f"âŒ ä¸æ”¯æŒçš„æ•°æ®æº: {data_source}")
            return

        log_area.text_area("", value="\n".join(logs), height=300, disabled=True)

        # 2. æ›´æ–°è‚¡ç¥¨åŸºç¡€ä¿¡æ¯
        total_progress.progress(10)
        total_status.text("æ›´æ–°è‚¡ç¥¨åŸºç¡€ä¿¡æ¯...")
        logs.append(f"[{datetime.now().strftime('%H:%M:%S')}] å¼€å§‹æ›´æ–°è‚¡ç¥¨åŸºç¡€ä¿¡æ¯...")
        log_area.text_area("", value="\n".join(logs), height=300, disabled=True)

        stock_basic_df = None
        try:
            if data_source.startswith("Tushare"):
                # ä½¿ç”¨Tushareè·å–è‚¡ç¥¨åŸºç¡€ä¿¡æ¯
                stock_basic_df = client.get_stock_basic()
                logs.append(f"[{datetime.now().strftime('%H:%M:%S')}] ä»Tushareè·å–åˆ° {len(stock_basic_df)} åªè‚¡ç¥¨åŸºç¡€ä¿¡æ¯")

            elif data_source == "AllTick":
                # AllTickè·å–è‚¡ç¥¨åŸºç¡€ä¿¡æ¯
                try:
                    stock_basic_df = client.get_stock_list('cn')  # è·å–ä¸­å›½å¸‚åœºè‚¡ç¥¨åˆ—è¡¨
                    logs.append(f"[{datetime.now().strftime('%H:%M:%S')}] ä»AllTickè·å–åˆ° {len(stock_basic_df)} åªè‚¡ç¥¨åŸºç¡€ä¿¡æ¯")
                except Exception as e:
                    logs.append(f"[{datetime.now().strftime('%H:%M:%S')}] âŒ AllTickè·å–è‚¡ç¥¨åŸºç¡€ä¿¡æ¯å¤±è´¥: {e}")
                    st.error(f"âŒ AllTickè·å–è‚¡ç¥¨åŸºç¡€ä¿¡æ¯å¤±è´¥: {e}")
                    return

            elif data_source == "Alpha Vantage":
                # Alpha Vantageä¸»è¦ç”¨äºç¾è‚¡
                logs.append(f"[{datetime.now().strftime('%H:%M:%S')}] âš ï¸ Alpha Vantageä¸»è¦ç”¨äºç¾è‚¡æ•°æ®")
                # è·å–å¸¸è§ç¾è‚¡åˆ—è¡¨ä½œä¸ºç¤ºä¾‹
                us_stocks = client.get_us_stock_list()
                stock_basic_data = []
                for symbol in us_stocks[:5]:  # åªè·å–å‰5åªä½œä¸ºç¤ºä¾‹
                    try:
                        basic_info = client.get_stock_basic(symbol)
                        if not basic_info.empty:
                            stock_basic_data.append(basic_info)
                    except Exception as e:
                        logs.append(f"[{datetime.now().strftime('%H:%M:%S')}] âš ï¸ è·å–{symbol}åŸºç¡€ä¿¡æ¯å¤±è´¥: {e}")

                if stock_basic_data:
                    stock_basic_df = pd.concat(stock_basic_data, ignore_index=True)
                    logs.append(f"[{datetime.now().strftime('%H:%M:%S')}] ä»Alpha Vantageè·å–åˆ° {len(stock_basic_df)} åªç¾è‚¡åŸºç¡€ä¿¡æ¯")
                else:
                    logs.append(f"[{datetime.now().strftime('%H:%M:%S')}] âŒ Alpha Vantageæœªè·å–åˆ°è‚¡ç¥¨åŸºç¡€ä¿¡æ¯")
                    st.error("âŒ Alpha Vantageæœªè·å–åˆ°è‚¡ç¥¨åŸºç¡€ä¿¡æ¯ï¼Œå¯èƒ½æ˜¯APIé™åˆ¶")
                    return

            if stock_basic_df is None or stock_basic_df.empty:
                logs.append(f"[{datetime.now().strftime('%H:%M:%S')}] âŒ æœªè·å–åˆ°è‚¡ç¥¨åŸºç¡€ä¿¡æ¯")
                st.error("âŒ æœªè·å–åˆ°è‚¡ç¥¨åŸºç¡€ä¿¡æ¯ï¼Œè¯·æ£€æŸ¥æ•°æ®æºé…ç½®")
                return

            # ä¿å­˜åˆ°æ•°æ®åº“
            if DB_AVAILABLE:
                db_manager = get_db_manager()
                try:
                    # ä½¿ç”¨SQLç›´æ¥æ’å…¥ï¼Œé¿å…pandaså…¼å®¹æ€§é—®é¢˜
                    insert_count = 0
                    for _, row in stock_basic_df.iterrows():
                        try:
                            insert_sql = """
                            INSERT INTO stock_basic (ts_code, symbol, name, area, industry, market, list_date, is_hs)
                            VALUES (%s, %s, %s, %s, %s, %s, %s, %s)
                            ON CONFLICT (ts_code) DO UPDATE SET
                            name = EXCLUDED.name,
                            area = EXCLUDED.area,
                            industry = EXCLUDED.industry,
                            market = EXCLUDED.market,
                            list_date = EXCLUDED.list_date,
                            is_hs = EXCLUDED.is_hs
                            """
                            db_manager.execute_postgres_query(insert_sql, params=(
                                row['ts_code'], row['symbol'], row['name'], row['area'],
                                row['industry'], row['market'], row['list_date'], row['is_hs']
                            ))
                            insert_count += 1
                        except Exception as insert_e:
                            logs.append(f"[{datetime.now().strftime('%H:%M:%S')}] âš ï¸ æ’å…¥è‚¡ç¥¨ {row['ts_code']} å¤±è´¥: {insert_e}")

                    logs.append(f"[{datetime.now().strftime('%H:%M:%S')}] âœ… æˆåŠŸä¿å­˜ {insert_count} åªè‚¡ç¥¨åŸºç¡€ä¿¡æ¯åˆ°æ•°æ®åº“")
                except Exception as db_e:
                    logs.append(f"[{datetime.now().strftime('%H:%M:%S')}] âŒ æ•°æ®åº“ä¿å­˜å¤±è´¥: {db_e}")
                    st.error(f"æ•°æ®åº“ä¿å­˜å¤±è´¥: {db_e}")
            else:
                logs.append(f"[{datetime.now().strftime('%H:%M:%S')}] âš ï¸ æ•°æ®åº“ä¸å¯ç”¨ï¼Œè·³è¿‡ä¿å­˜")

        except Exception as e:
            error_msg = str(e)
            if "æƒé™" in error_msg or "permission" in error_msg.lower():
                logs.append(f"[{datetime.now().strftime('%H:%M:%S')}] âŒ APIæƒé™ä¸è¶³: {error_msg}")
                st.error(f"âŒ æ›´æ–°è‚¡ç¥¨åŸºç¡€ä¿¡æ¯å¤±è´¥ï¼šAPIæƒé™ä¸è¶³ - {error_msg}")
            elif "limit" in error_msg.lower() or "quota" in error_msg.lower():
                logs.append(f"[{datetime.now().strftime('%H:%M:%S')}] âŒ APIè°ƒç”¨é™åˆ¶: {error_msg}")
                st.error(f"âŒ æ›´æ–°è‚¡ç¥¨åŸºç¡€ä¿¡æ¯å¤±è´¥ï¼šAPIè°ƒç”¨è¶…é™ - {error_msg}")
            else:
                logs.append(f"[{datetime.now().strftime('%H:%M:%S')}] âŒ æ›´æ–°è‚¡ç¥¨åŸºç¡€ä¿¡æ¯å¤±è´¥: {error_msg}")
                st.error(f"âŒ æ›´æ–°è‚¡ç¥¨åŸºç¡€ä¿¡æ¯å¤±è´¥: {error_msg}")
            return

        log_area.text_area("", value="\n".join(logs), height=300, disabled=True)

        # 3. æ›´æ–°æ—¥çº¿è¡Œæƒ…æ•°æ®
        total_progress.progress(30)
        total_status.text("æ›´æ–°æ—¥çº¿è¡Œæƒ…æ•°æ®...")

        # ç¡®å®šè¦æ›´æ–°çš„æ—¥æœŸ
        if update_type == "æŒ‡å®šæ—¥æœŸ" and target_date:
            trade_dates = [target_date.strftime('%Y%m%d')]
        elif update_type == "å¢é‡æ›´æ–°":
            # è·å–æœ€è¿‘5ä¸ªäº¤æ˜“æ—¥
            trade_dates = get_recent_trade_dates(5)
        else:
            # é»˜è®¤æ›´æ–°6æœˆ13æ—¥
            trade_dates = ['20240613']

        logs.append(f"[{datetime.now().strftime('%H:%M:%S')}] å‡†å¤‡æ›´æ–°æ—¥æœŸ: {', '.join(trade_dates)}")
        log_area.text_area("", value="\n".join(logs), height=300, disabled=True)

        # è·å–è‚¡ç¥¨åˆ—è¡¨
        if update_scope == "è‡ªå®šä¹‰é€‰æ‹©" and selected_stocks:
            stock_list = selected_stocks
        else:
            # ä»æ•°æ®åº“è·å–è‚¡ç¥¨åˆ—è¡¨
            if DB_AVAILABLE and stock_basic_df is not None and not stock_basic_df.empty:
                try:
                    # ä¼˜å…ˆä½¿ç”¨åˆšè·å–çš„è‚¡ç¥¨åŸºç¡€ä¿¡æ¯
                    if update_scope == "æ²ªæ·±300":
                        stock_list = stock_basic_df.head(300)['ts_code'].tolist()
                    elif update_scope == "ä¸­è¯500":
                        stock_list = stock_basic_df.head(500)['ts_code'].tolist()
                    elif update_scope == "åˆ›ä¸šæ¿50":
                        stock_list = stock_basic_df[stock_basic_df['market'] == 'åˆ›ä¸šæ¿'].head(50)['ts_code'].tolist()
                    elif update_scope == "ç§‘åˆ›æ¿50":
                        stock_list = stock_basic_df[stock_basic_df['market'] == 'ç§‘åˆ›æ¿'].head(50)['ts_code'].tolist()
                    else:
                        stock_list = stock_basic_df['ts_code'].tolist()
                except Exception as e:
                    logs.append(f"[{datetime.now().strftime('%H:%M:%S')}] âš ï¸ ä»åŸºç¡€ä¿¡æ¯è·å–è‚¡ç¥¨åˆ—è¡¨å¤±è´¥: {e}")
                    # å¤‡é€‰ï¼šä»æ•°æ®åº“è·å–
                    try:
                        db_manager = get_db_manager()
                        stock_query = "SELECT ts_code FROM stock_basic WHERE is_hs = 'Y' LIMIT 100"
                        stock_df = db_manager.execute_postgres_query(stock_query)
                        stock_list = stock_df['ts_code'].tolist() if not stock_df.empty else []
                    except Exception as db_e:
                        logs.append(f"[{datetime.now().strftime('%H:%M:%S')}] âš ï¸ ä»æ•°æ®åº“è·å–è‚¡ç¥¨åˆ—è¡¨ä¹Ÿå¤±è´¥: {db_e}")
                        stock_list = ['000001.SZ', '000002.SZ', '600000.SH', '600036.SH', '000858.SZ']
            else:
                # ä½¿ç”¨é¢„å®šä¹‰çš„è‚¡ç¥¨åˆ—è¡¨
                stock_list = [
                    '000001.SZ', '000002.SZ', '000858.SZ', '600000.SH', '600036.SH',
                    '600519.SH', '300750.SZ', '002415.SZ', '600104.SH', '000725.SZ'
                ]
                logs.append(f"[{datetime.now().strftime('%H:%M:%S')}] ä½¿ç”¨é¢„å®šä¹‰è‚¡ç¥¨åˆ—è¡¨")

        if not stock_list:
            logs.append(f"[{datetime.now().strftime('%H:%M:%S')}] âŒ è‚¡ç¥¨åˆ—è¡¨ä¸ºç©ºï¼Œæ— æ³•æ›´æ–°è¡Œæƒ…æ•°æ®")
            st.error("âŒ è‚¡ç¥¨åˆ—è¡¨ä¸ºç©ºï¼Œæ— æ³•æ›´æ–°è¡Œæƒ…æ•°æ®")
            return

        logs.append(f"[{datetime.now().strftime('%H:%M:%S')}] å‡†å¤‡æ›´æ–° {len(stock_list)} åªè‚¡ç¥¨çš„è¡Œæƒ…æ•°æ®")
        log_area.text_area("", value="\n".join(logs), height=300, disabled=True)

        # æ‰¹é‡æ›´æ–°è¡Œæƒ…æ•°æ®
        total_records = 0
        for date_idx, trade_date in enumerate(trade_dates):
            date_progress = 30 + (date_idx * 60 // len(trade_dates))
            total_progress.progress(date_progress)
            total_status.text(f"æ›´æ–° {trade_date} è¡Œæƒ…æ•°æ®...")

            logs.append(f"[{datetime.now().strftime('%H:%M:%S')}] å¼€å§‹æ›´æ–° {trade_date} çš„è¡Œæƒ…æ•°æ®")
            log_area.text_area("", value="\n".join(logs), height=300, disabled=True)

            quotes_df = None
            try:
                if data_source.startswith("Tushare"):
                    # ä½¿ç”¨Tushareæ‰¹é‡è·å–è¡Œæƒ…æ•°æ®
                    quotes_df = client.batch_get_daily_quotes(stock_list, trade_date)

                elif data_source == "AllTick":
                    # AllTickè·å–è¡Œæƒ…æ•°æ®
                    logs.append(f"[{datetime.now().strftime('%H:%M:%S')}] å°è¯•ä»AllTickè·å– {trade_date} è¡Œæƒ…æ•°æ®...")
                    try:
                        # è¿™é‡Œåº”è¯¥è°ƒç”¨AllTickçš„è¡Œæƒ…æ•°æ®æ¥å£
                        # quotes_df = client.get_daily_quotes(stock_list, trade_date)
                        logs.append(f"[{datetime.now().strftime('%H:%M:%S')}] âŒ AllTickè¡Œæƒ…æ•°æ®æ¥å£æš‚æœªå®ç°")
                        st.error("âŒ AllTickè¡Œæƒ…æ•°æ®æ¥å£æš‚æœªå®ç°ï¼Œè¯·ä½¿ç”¨Tushare")
                        continue
                    except Exception as alltick_e:
                        logs.append(f"[{datetime.now().strftime('%H:%M:%S')}] âŒ AllTickè·å–è¡Œæƒ…å¤±è´¥: {alltick_e}")
                        continue

                elif data_source == "Alpha Vantage":
                    # Alpha Vantageè·å–è¡Œæƒ…æ•°æ®ï¼ˆä¸»è¦ç”¨äºç¾è‚¡ï¼‰
                    logs.append(f"[{datetime.now().strftime('%H:%M:%S')}] âŒ Alpha Vantageä¸æ”¯æŒAè‚¡è¡Œæƒ…æ•°æ®")
                    st.error("âŒ Alpha Vantageä¸»è¦ç”¨äºç¾è‚¡æ•°æ®ï¼Œä¸æ”¯æŒAè‚¡è¡Œæƒ…ï¼Œè¯·ä½¿ç”¨Tushareæˆ–AllTick")
                    continue

                if quotes_df is None or quotes_df.empty:
                    logs.append(f"[{datetime.now().strftime('%H:%M:%S')}] âš ï¸ {trade_date}: æœªè·å–åˆ°è¡Œæƒ…æ•°æ®ï¼ˆå¯èƒ½æ˜¯éäº¤æ˜“æ—¥ï¼‰")
                    continue

                logs.append(f"[{datetime.now().strftime('%H:%M:%S')}] ä»{data_source}è·å–åˆ° {len(quotes_df)} æ¡ {trade_date} è¡Œæƒ…æ•°æ®")

                # ä¿å­˜åˆ°æ•°æ®åº“
                if DB_AVAILABLE:
                    try:
                        # ä½¿ç”¨SQLç›´æ¥æ’å…¥ï¼Œé¿å…pandaså…¼å®¹æ€§é—®é¢˜
                        insert_count = 0
                        for _, row in quotes_df.iterrows():
                            try:
                                insert_sql = """
                                INSERT INTO stock_daily_quotes
                                (ts_code, trade_date, open_price, high_price, low_price, close_price,
                                 pre_close, change_amount, pct_chg, vol, amount)
                                VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                                ON CONFLICT (ts_code, trade_date) DO UPDATE SET
                                open_price = EXCLUDED.open_price,
                                high_price = EXCLUDED.high_price,
                                low_price = EXCLUDED.low_price,
                                close_price = EXCLUDED.close_price,
                                pre_close = EXCLUDED.pre_close,
                                change_amount = EXCLUDED.change_amount,
                                pct_chg = EXCLUDED.pct_chg,
                                vol = EXCLUDED.vol,
                                amount = EXCLUDED.amount
                                """
                                db_manager.execute_postgres_query(insert_sql, params=(
                                    row['ts_code'], row['trade_date'], row['open_price'], row['high_price'],
                                    row['low_price'], row['close_price'], row['pre_close'], row['change_amount'],
                                    row['pct_chg'], row['vol'], row['amount']
                                ))
                                insert_count += 1
                            except Exception as insert_e:
                                logs.append(f"[{datetime.now().strftime('%H:%M:%S')}] âš ï¸ æ’å…¥ {row['ts_code']} {trade_date} è¡Œæƒ…å¤±è´¥: {insert_e}")

                        total_records += insert_count
                        logs.append(f"[{datetime.now().strftime('%H:%M:%S')}] âœ… {trade_date}: æˆåŠŸä¿å­˜ {insert_count} æ¡è®°å½•")
                    except Exception as db_e:
                        logs.append(f"[{datetime.now().strftime('%H:%M:%S')}] âŒ {trade_date}: æ•°æ®åº“ä¿å­˜å¤±è´¥ - {db_e}")
                else:
                    logs.append(f"[{datetime.now().strftime('%H:%M:%S')}] âš ï¸ æ•°æ®åº“ä¸å¯ç”¨ï¼Œè·³è¿‡ä¿å­˜")

            except Exception as e:
                error_msg = str(e)
                if "æƒé™" in error_msg or "permission" in error_msg.lower():
                    logs.append(f"[{datetime.now().strftime('%H:%M:%S')}] âŒ {trade_date}: APIæƒé™ä¸è¶³ - {error_msg}")
                elif "limit" in error_msg.lower() or "quota" in error_msg.lower():
                    logs.append(f"[{datetime.now().strftime('%H:%M:%S')}] âŒ {trade_date}: APIè°ƒç”¨è¶…é™ - {error_msg}")
                elif "timeout" in error_msg.lower():
                    logs.append(f"[{datetime.now().strftime('%H:%M:%S')}] âŒ {trade_date}: è¯·æ±‚è¶…æ—¶ - {error_msg}")
                else:
                    logs.append(f"[{datetime.now().strftime('%H:%M:%S')}] âŒ {trade_date}: æ›´æ–°å¤±è´¥ - {error_msg}")

            log_area.text_area("", value="\n".join(logs), height=300, disabled=True)

        # 4. å®Œæˆ
        total_progress.progress(100)
        total_status.text("âœ… æ•°æ®æ›´æ–°å®Œæˆ!")
        logs.append(f"[{datetime.now().strftime('%H:%M:%S')}] ğŸ‰ æ•°æ®æ›´æ–°å®Œæˆ!")
        logs.append(f"[{datetime.now().strftime('%H:%M:%S')}] æ€»è®¡æ›´æ–°: {len(stock_list)} åªè‚¡ç¥¨, {len(trade_dates)} ä¸ªäº¤æ˜“æ—¥, {total_records} æ¡è®°å½•")
        log_area.text_area("", value="\n".join(logs), height=300, disabled=True)

        # æ¸…é™¤ç¼“å­˜
        st.cache_data.clear()

        # æ˜¾ç¤ºæˆåŠŸä¿¡æ¯
        with progress_container:
            st.success(f"âœ… æ•°æ®æ›´æ–°æˆåŠŸ!")

            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("æ›´æ–°è‚¡ç¥¨", f"{len(stock_list):,}")
            with col2:
                st.metric("æ›´æ–°æ—¥æœŸ", len(trade_dates))
            with col3:
                st.metric("æ€»è®°å½•æ•°", f"{total_records:,}")
            with col4:
                st.metric("æ•°æ®æº", data_source)

    except Exception as e:
        logs.append(f"[{datetime.now().strftime('%H:%M:%S')}] âŒ æ•°æ®æ›´æ–°å¤±è´¥: {e}")
        log_area.text_area("", value="\n".join(logs), height=300, disabled=True)
        st.error(f"âŒ æ•°æ®æ›´æ–°å¤±è´¥: {e}")


def get_recent_trade_dates(days=5):
    """è·å–æœ€è¿‘çš„äº¤æ˜“æ—¥æœŸ"""
    dates = []
    current_date = datetime.now()

    while len(dates) < days:
        # è·³è¿‡å‘¨æœ«
        if current_date.weekday() < 5:  # 0-4 æ˜¯å‘¨ä¸€åˆ°å‘¨äº”
            dates.append(current_date.strftime('%Y%m%d'))
        current_date -= timedelta(days=1)

    return dates[::-1]  # è¿”å›æ­£åº


def simulate_data_update(logs, log_area, total_progress, total_status, detail_progress, detail_status):
    """æ¨¡æ‹Ÿæ•°æ®æ›´æ–°è¿‡ç¨‹"""
    import time

    logs.append(f"[{datetime.now().strftime('%H:%M:%S')}] ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®æ›´æ–°æ¨¡å¼")
    log_area.text_area("", value="\n".join(logs), height=300, disabled=True)

    # æ¨¡æ‹Ÿæ›´æ–°è¿‡ç¨‹
    for i in range(100):
        total_progress.progress(i + 1)
        total_status.text(f"æ¨¡æ‹Ÿæ›´æ–°ä¸­... {i+1}%")

        if i % 20 == 0:
            logs.append(f"[{datetime.now().strftime('%H:%M:%S')}] æ¨¡æ‹Ÿè¿›åº¦: {i+1}%")
            log_area.text_area("", value="\n".join(logs), height=300, disabled=True)

        time.sleep(0.02)

    logs.append(f"[{datetime.now().strftime('%H:%M:%S')}] âœ… æ¨¡æ‹Ÿæ›´æ–°å®Œæˆ")
    log_area.text_area("", value="\n".join(logs), height=300, disabled=True)


@st.cache_data(ttl=300)
def get_stock_list():
    """è·å–è‚¡ç¥¨åˆ—è¡¨"""
    try:
        # ä¼˜å…ˆå°è¯•ä»æ•°æ®åº“è·å–çœŸå®æ•°æ®
        if DB_AVAILABLE:
            try:
                db_manager = get_db_manager()
                query = """
                SELECT ts_code, symbol, name, area, industry, market, list_date
                FROM stock_basic
                WHERE is_hs = 'Y' AND market IN ('ä¸»æ¿', 'åˆ›ä¸šæ¿', 'ç§‘åˆ›æ¿')
                ORDER BY ts_code
                """
                df = db_manager.execute_postgres_query(query)

                if not df.empty:
                    logger.info(f"ä»æ•°æ®åº“è·å–åˆ° {len(df)} åªè‚¡ç¥¨æ•°æ®")
                    return df
                else:
                    logger.warning("æ•°æ®åº“ä¸­æ— è‚¡ç¥¨æ•°æ®ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")

            except Exception as e:
                logger.error(f"æ•°æ®åº“æŸ¥è¯¢å¤±è´¥: {e}ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")

        # å¤‡é€‰æ–¹æ¡ˆï¼šä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®
        logger.info("ä½¿ç”¨æ¨¡æ‹Ÿè‚¡ç¥¨æ•°æ®")
        stock_codes = [
            "000001.SZ", "000002.SZ", "000858.SZ", "000876.SZ", "002415.SZ",
            "600000.SH", "600036.SH", "600519.SH", "600887.SH", "601318.SH",
            "688001.SH", "688036.SH", "688111.SH", "688188.SH", "688599.SH"
        ]

        stock_names = [
            "å¹³å®‰é“¶è¡Œ", "ä¸‡ç§‘A", "äº”ç²®æ¶²", "æ–°å¸Œæœ›", "æ¬§è²å…‰",
            "æµ¦å‘é“¶è¡Œ", "æ‹›å•†é“¶è¡Œ", "è´µå·èŒ…å°", "ä¼Šåˆ©è‚¡ä»½", "ä¸­å›½å¹³å®‰",
            "åå…´æºåˆ›", "ä¼ éŸ³æ§è‚¡", "é‡‘å±±åŠå…¬", "æŸæ¥šç”µå­", "å¤©åˆå…‰èƒ½"
        ]

        industries = [
            "é“¶è¡Œ", "æˆ¿åœ°äº§", "é£Ÿå“é¥®æ–™", "å†œæ—ç‰§æ¸”", "ç”µå­",
            "é“¶è¡Œ", "é“¶è¡Œ", "é£Ÿå“é¥®æ–™", "é£Ÿå“é¥®æ–™", "éé“¶é‡‘è",
            "ç”µå­", "ç”µå­", "è®¡ç®—æœº", "æœºæ¢°è®¾å¤‡", "ç”µåŠ›è®¾å¤‡"
        ]

        markets = [
            "ä¸»æ¿", "ä¸»æ¿", "ä¸»æ¿", "ä¸»æ¿", "åˆ›ä¸šæ¿",
            "ä¸»æ¿", "ä¸»æ¿", "ä¸»æ¿", "ä¸»æ¿", "ä¸»æ¿",
            "ç§‘åˆ›æ¿", "ç§‘åˆ›æ¿", "ç§‘åˆ›æ¿", "ç§‘åˆ›æ¿", "ç§‘åˆ›æ¿"
        ]

        areas = [
            "å¹¿ä¸œ", "å¹¿ä¸œ", "å››å·", "å››å·", "å¹¿ä¸œ",
            "ä¸Šæµ·", "å¹¿ä¸œ", "è´µå·", "å†…è’™å¤", "å¹¿ä¸œ",
            "æ±Ÿè‹", "å¹¿ä¸œ", "åŒ—äº¬", "ä¸Šæµ·", "æ±Ÿè‹"
        ]

        df = pd.DataFrame({
            'ts_code': stock_codes,
            'symbol': [code.split('.')[0] for code in stock_codes],
            'name': stock_names,
            'area': areas,
            'industry': industries,
            'market': markets,
            'list_date': ['2020-01-01'] * len(stock_codes)
        })

        return df

    except Exception as e:
        logger.error(f"è·å–è‚¡ç¥¨åˆ—è¡¨å¤±è´¥: {e}")
        return pd.DataFrame()


@st.cache_data(ttl=60)
def get_latest_data_status():
    """è·å–æœ€æ–°æ•°æ®çŠ¶æ€"""
    try:
        # ä¼˜å…ˆå°è¯•ä»æ•°æ®åº“è·å–çœŸå®æ•°æ®çŠ¶æ€
        if DB_AVAILABLE:
            try:
                db_manager = get_db_manager()

                # è·å–æœ€æ–°äº¤æ˜“æ—¥æœŸ
                query = """
                SELECT
                    MAX(trade_date) as latest_date,
                    COUNT(DISTINCT ts_code) as stock_count,
                    COUNT(*) as total_records
                FROM stock_daily_quotes
                """
                result = db_manager.execute_postgres_query(query)

                if not result.empty:
                    latest_date = result['latest_date'].iloc[0]
                    stock_count = result['stock_count'].iloc[0]
                    total_records = result['total_records'].iloc[0]

                    logger.info(f"ä»æ•°æ®åº“è·å–æ•°æ®çŠ¶æ€: æœ€æ–°æ—¥æœŸ={latest_date}, è‚¡ç¥¨æ•°={stock_count}, è®°å½•æ•°={total_records}")

                    return {
                        "latest_date": latest_date,
                        "stock_count": stock_count,
                        "total_records": total_records,
                        "is_today": latest_date == datetime.now().date() if latest_date else False
                    }

            except Exception as e:
                logger.error(f"æ•°æ®åº“æŸ¥è¯¢å¤±è´¥: {e}ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®çŠ¶æ€")

        # å¤‡é€‰æ–¹æ¡ˆï¼šä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®çŠ¶æ€
        logger.info("ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®çŠ¶æ€")
        latest_date = datetime.now().date() - timedelta(days=1)  # æ˜¨å¤©çš„æ•°æ®
        stock_count = 15  # æ¨¡æ‹Ÿ15åªè‚¡ç¥¨
        total_records = 1500  # æ¨¡æ‹Ÿ1500æ¡è®°å½•

        return {
            "latest_date": latest_date,
            "stock_count": stock_count,
            "total_records": total_records,
            "is_today": False  # ä¸æ˜¯ä»Šå¤©çš„æ•°æ®
        }

    except Exception as e:
        logger.error(f"è·å–æ•°æ®çŠ¶æ€å¤±è´¥: {e}")
        return {
            "latest_date": None,
            "stock_count": 0,
            "total_records": 0,
            "is_today": False
        }


def render_data_overview():
    """æ¸²æŸ“æ•°æ®æ¦‚è§ˆ"""
    st.header("ğŸ“Š æ•°æ®æ¦‚è§ˆ")
    
    # è·å–æ•°æ®çŠ¶æ€
    data_status = get_latest_data_status()
    stock_list = get_stock_list()
    
    # æ•°æ®çŠ¶æ€æŒ‡æ ‡
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        latest_date = data_status["latest_date"]
        if latest_date:
            date_str = latest_date.strftime('%Y-%m-%d')
            delta_color = "normal" if data_status["is_today"] else "inverse"
            delta_text = "ä»Šæ—¥æ•°æ®" if data_status["is_today"] else "éœ€è¦æ›´æ–°"
        else:
            date_str = "æ— æ•°æ®"
            delta_color = "inverse"
            delta_text = "éœ€è¦åˆå§‹åŒ–"
        
        st.metric(
            "æœ€æ–°æ•°æ®æ—¥æœŸ",
            date_str,
            delta=delta_text,
            delta_color=delta_color
        )
    
    with col2:
        st.metric(
            "è‚¡ç¥¨æ•°é‡",
            f"{data_status['stock_count']:,}",
            delta=f"æ€»è®¡ {len(stock_list):,} åª"
        )
    
    with col3:
        st.metric(
            "è¡Œæƒ…è®°å½•æ•°",
            f"{data_status['total_records']:,}",
            delta="æ¡è®°å½•"
        )
    
    with col4:
        coverage = (data_status['stock_count'] / len(stock_list) * 100) if len(stock_list) > 0 else 0
        st.metric(
            "æ•°æ®è¦†ç›–ç‡",
            f"{coverage:.1f}%",
            delta="è‚¡ç¥¨è¦†ç›–"
        )


def render_data_update():
    """æ¸²æŸ“æ•°æ®æ›´æ–°åŠŸèƒ½"""
    st.header("ğŸ”„ æ•°æ®æ›´æ–°")
    
    # æ•°æ®æºé€‰æ‹©
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ğŸ“¡ æ•°æ®æºé…ç½®")
        
        # æ„å»ºå¯ç”¨æ•°æ®æºåˆ—è¡¨
        available_sources = []
        if TUSHARE_AVAILABLE:
            available_sources.append("Tushare (æ¨è)")
        if ALLTICK_AVAILABLE:
            available_sources.append("AllTick")
        if ALPHA_VANTAGE_AVAILABLE:
            available_sources.append("Alpha Vantage")
        available_sources.append("æ¨¡æ‹Ÿæ•°æ®")

        data_source = st.selectbox(
            "é€‰æ‹©æ•°æ®æº",
            available_sources,
            index=0
        )
        
        update_type = st.selectbox(
            "æ›´æ–°ç±»å‹",
            ["å¢é‡æ›´æ–°", "å…¨é‡æ›´æ–°", "æŒ‡å®šæ—¥æœŸ"],
            index=0
        )
        
        if update_type == "æŒ‡å®šæ—¥æœŸ":
            target_date = st.date_input(
                "ç›®æ ‡æ—¥æœŸ",
                value=datetime.now().date(),
                max_value=datetime.now().date()
            )
        else:
            target_date = None
    
    with col2:
        st.subheader("ğŸ“ˆ æ›´æ–°èŒƒå›´")
        
        update_scope = st.selectbox(
            "æ›´æ–°èŒƒå›´",
            ["å…¨éƒ¨è‚¡ç¥¨", "ä¸»æ¿è‚¡ç¥¨", "åˆ›ä¸šæ¿è‚¡ç¥¨", "ç§‘åˆ›æ¿è‚¡ç¥¨", "è‡ªå®šä¹‰é€‰æ‹©"],
            index=0
        )
        
        if update_scope == "è‡ªå®šä¹‰é€‰æ‹©":
            stock_list = get_stock_list()
            if not stock_list.empty:
                selected_stocks = st.multiselect(
                    "é€‰æ‹©è‚¡ç¥¨",
                    options=stock_list['ts_code'].tolist(),
                    format_func=lambda x: f"{x} - {stock_list[stock_list['ts_code']==x]['name'].iloc[0] if not stock_list[stock_list['ts_code']==x].empty else x}"
                )
            else:
                selected_stocks = []
                st.warning("æ— æ³•è·å–è‚¡ç¥¨åˆ—è¡¨")
        else:
            selected_stocks = None
    
    # æ›´æ–°æŒ‰é’®
    col1, col2, col3 = st.columns(3)

    with col1:
        if st.button("ğŸš€ å¼€å§‹æ›´æ–°", type="primary"):
            execute_real_data_update(
                data_source, update_type, target_date,
                update_scope, selected_stocks
            )
    
    with col2:
        if st.button("ğŸ“Š éªŒè¯æ•°æ®"):
            with st.spinner("æ­£åœ¨éªŒè¯æ•°æ®å®Œæ•´æ€§..."):
                try:
                    # æ¨¡æ‹Ÿæ•°æ®éªŒè¯é€»è¾‘
                    # TODO: ä¿®å¤æ•°æ®åº“è¿æ¥åæ›¿æ¢ä¸ºçœŸå®éªŒè¯

                    validation_results = []

                    # æ¨¡æ‹Ÿæ£€æŸ¥åŸºç¡€æ•°æ®
                    stock_count = 15  # æ¨¡æ‹Ÿè‚¡ç¥¨æ•°é‡
                    validation_results.append({
                        "æ£€æŸ¥é¡¹": "è‚¡ç¥¨åŸºç¡€ä¿¡æ¯",
                        "ç»“æœ": f"{stock_count:,} æ¡è®°å½•",
                        "çŠ¶æ€": "âš ï¸ æ¨¡æ‹Ÿæ•°æ®"
                    })

                    # æ¨¡æ‹Ÿæ£€æŸ¥è¡Œæƒ…æ•°æ®
                    quote_count = 1500  # æ¨¡æ‹Ÿè¡Œæƒ…æ•°æ®
                    validation_results.append({
                        "æ£€æŸ¥é¡¹": "æ—¥çº¿è¡Œæƒ…æ•°æ®",
                        "ç»“æœ": f"{quote_count:,} æ¡è®°å½•",
                        "çŠ¶æ€": "âš ï¸ æ¨¡æ‹Ÿæ•°æ®"
                    })

                    # æ˜¾ç¤ºéªŒè¯ç»“æœ
                    df = pd.DataFrame(validation_results)
                    st.dataframe(df, use_container_width=True)
                    st.warning("å½“å‰æ˜¾ç¤ºçš„æ˜¯æ¨¡æ‹Ÿæ•°æ®éªŒè¯ç»“æœï¼Œè¯·ä¿®å¤æ•°æ®åº“è¿æ¥åæŸ¥çœ‹çœŸå®æ•°æ®")

                except Exception as e:
                    st.error(f"æ•°æ®éªŒè¯å¤±è´¥: {e}")
    
    with col3:
        if st.button("ğŸ§¹ æ¸…ç†æ•°æ®"):
            if st.checkbox("ç¡®è®¤æ¸…ç†ï¼ˆä¸å¯æ¢å¤ï¼‰"):
                with st.spinner("æ­£åœ¨æ¸…ç†æ•°æ®..."):
                    try:
                        # æ•°æ®æ¸…ç†é€»è¾‘
                        st.warning("æ•°æ®æ¸…ç†åŠŸèƒ½æš‚æœªå®ç°")
                    except Exception as e:
                        st.error(f"æ•°æ®æ¸…ç†å¤±è´¥: {e}")


def render_stock_selector():
    """æ¸²æŸ“è‚¡ç¥¨é€‰æ‹©å™¨"""
    st.header("ğŸ¯ è‚¡ç¥¨é€‰æ‹©å™¨")
    
    stock_list = get_stock_list()
    
    if stock_list.empty:
        st.warning("æ— æ³•è·å–è‚¡ç¥¨åˆ—è¡¨ï¼Œè¯·æ£€æŸ¥æ•°æ®åº“è¿æ¥")
        return []
    
    # ç­›é€‰æ¡ä»¶
    col1, col2, col3 = st.columns(3)
    
    with col1:
        # å¸‚åœºç­›é€‰
        markets = ['å…¨éƒ¨'] + stock_list['market'].unique().tolist()
        selected_market = st.selectbox("å¸‚åœº", markets)
    
    with col2:
        # è¡Œä¸šç­›é€‰
        industries = ['å…¨éƒ¨'] + stock_list['industry'].unique().tolist()
        selected_industry = st.selectbox("è¡Œä¸š", industries)
    
    with col3:
        # åœ°åŒºç­›é€‰
        areas = ['å…¨éƒ¨'] + stock_list['area'].unique().tolist()
        selected_area = st.selectbox("åœ°åŒº", areas)
    
    # åº”ç”¨ç­›é€‰
    filtered_stocks = stock_list.copy()
    
    if selected_market != 'å…¨éƒ¨':
        filtered_stocks = filtered_stocks[filtered_stocks['market'] == selected_market]
    
    if selected_industry != 'å…¨éƒ¨':
        filtered_stocks = filtered_stocks[filtered_stocks['industry'] == selected_industry]
    
    if selected_area != 'å…¨éƒ¨':
        filtered_stocks = filtered_stocks[filtered_stocks['area'] == selected_area]
    
    # æœç´¢æ¡†
    search_term = st.text_input("ğŸ” æœç´¢è‚¡ç¥¨ï¼ˆä»£ç æˆ–åç§°ï¼‰")
    if search_term:
        mask = (
            filtered_stocks['ts_code'].str.contains(search_term, case=False, na=False) |
            filtered_stocks['name'].str.contains(search_term, case=False, na=False) |
            filtered_stocks['symbol'].str.contains(search_term, case=False, na=False)
        )
        filtered_stocks = filtered_stocks[mask]
    
    # æ˜¾ç¤ºç­›é€‰ç»“æœ
    st.write(f"æ‰¾åˆ° {len(filtered_stocks)} åªè‚¡ç¥¨")
    
    if not filtered_stocks.empty:
        # åˆ†é¡µæ˜¾ç¤º
        page_size = 20
        total_pages = (len(filtered_stocks) - 1) // page_size + 1
        
        if total_pages > 1:
            page = st.selectbox("é¡µç ", range(1, total_pages + 1))
            start_idx = (page - 1) * page_size
            end_idx = start_idx + page_size
            display_stocks = filtered_stocks.iloc[start_idx:end_idx]
        else:
            display_stocks = filtered_stocks
        
        # æ˜¾ç¤ºè‚¡ç¥¨åˆ—è¡¨
        selected_stocks = st.multiselect(
            "é€‰æ‹©è¦åˆ†æçš„è‚¡ç¥¨",
            options=display_stocks['ts_code'].tolist(),
            format_func=lambda x: f"{x} - {display_stocks[display_stocks['ts_code']==x]['name'].iloc[0]}"
        )
        
        # æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
        if selected_stocks:
            st.subheader("ğŸ“‹ é€‰ä¸­çš„è‚¡ç¥¨")
            selected_df = display_stocks[display_stocks['ts_code'].isin(selected_stocks)]
            st.dataframe(
                selected_df[['ts_code', 'name', 'industry', 'market', 'area']],
                use_container_width=True
            )
            
            return selected_stocks
        else:
            # æ˜¾ç¤ºç­›é€‰ç»“æœè¡¨æ ¼
            st.dataframe(
                display_stocks[['ts_code', 'name', 'industry', 'market', 'area']],
                use_container_width=True
            )
    
    return []


def render_data_export():
    """æ¸²æŸ“æ•°æ®å¯¼å‡ºåŠŸèƒ½"""
    st.header("ğŸ“¤ æ•°æ®å¯¼å‡º")
    
    # å¯¼å‡ºé€‰é¡¹
    col1, col2 = st.columns(2)
    
    with col1:
        export_type = st.selectbox(
            "å¯¼å‡ºç±»å‹",
            ["è‚¡ç¥¨åŸºç¡€ä¿¡æ¯", "æ—¥çº¿è¡Œæƒ…æ•°æ®", "äº¤æ˜“ä¿¡å·", "æŠ€æœ¯æŒ‡æ ‡", "è‡ªå®šä¹‰æŸ¥è¯¢"]
        )
        
        export_format = st.selectbox(
            "å¯¼å‡ºæ ¼å¼",
            ["CSV", "Excel", "JSON"]
        )
    
    with col2:
        if export_type != "è‡ªå®šä¹‰æŸ¥è¯¢":
            date_range = st.date_input(
                "æ—¥æœŸèŒƒå›´",
                value=[datetime.now().date() - timedelta(days=30), datetime.now().date()],
                max_value=datetime.now().date()
            )
        
        if export_type in ["æ—¥çº¿è¡Œæƒ…æ•°æ®", "äº¤æ˜“ä¿¡å·", "æŠ€æœ¯æŒ‡æ ‡"]:
            stock_codes = st.text_area(
                "è‚¡ç¥¨ä»£ç ï¼ˆæ¯è¡Œä¸€ä¸ªï¼‰",
                placeholder="000001.SZ\n000002.SZ\n600000.SH"
            )
    
    # è‡ªå®šä¹‰æŸ¥è¯¢
    if export_type == "è‡ªå®šä¹‰æŸ¥è¯¢":
        custom_query = st.text_area(
            "SQLæŸ¥è¯¢è¯­å¥",
            placeholder="SELECT * FROM stock_basic LIMIT 100",
            height=100
        )
    
    # å¯¼å‡ºæŒ‰é’®
    if st.button("ğŸ“¥ å¯¼å‡ºæ•°æ®", type="primary"):
        try:
            # æš‚æ—¶ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®å¯¼å‡º
            # TODO: ä¿®å¤æ•°æ®åº“è¿æ¥åæ›¿æ¢ä¸ºçœŸå®æ•°æ®å¯¼å‡º

            if export_type == "è‡ªå®šä¹‰æŸ¥è¯¢":
                if custom_query and custom_query.strip():
                    st.warning("è‡ªå®šä¹‰æŸ¥è¯¢åŠŸèƒ½éœ€è¦æ•°æ®åº“è¿æ¥ï¼Œå½“å‰ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")
                    df = get_stock_list()  # ä½¿ç”¨æ¨¡æ‹Ÿè‚¡ç¥¨åˆ—è¡¨
                else:
                    st.error("è¯·è¾“å…¥SQLæŸ¥è¯¢è¯­å¥")
                    return
            else:
                # æ ¹æ®å¯¼å‡ºç±»å‹ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®
                if export_type == "è‚¡ç¥¨åŸºç¡€ä¿¡æ¯":
                    df = get_stock_list()
                else:
                    st.warning("å…¶ä»–å¯¼å‡ºç±»å‹æš‚æœªå®ç°ï¼Œå½“å‰ä½¿ç”¨è‚¡ç¥¨åŸºç¡€ä¿¡æ¯ä½œä¸ºç¤ºä¾‹")
                    df = get_stock_list()
            
            if not df.empty:
                # æ ¹æ®æ ¼å¼å¯¼å‡º
                if export_format == "CSV":
                    csv = df.to_csv(index=False)
                    st.download_button(
                        label="ä¸‹è½½CSVæ–‡ä»¶",
                        data=csv,
                        file_name=f"{export_type}_{datetime.now().strftime('%Y%m%d')}.csv",
                        mime="text/csv"
                    )
                elif export_format == "JSON":
                    json_str = df.to_json(orient='records', indent=2)
                    st.download_button(
                        label="ä¸‹è½½JSONæ–‡ä»¶",
                        data=json_str,
                        file_name=f"{export_type}_{datetime.now().strftime('%Y%m%d')}.json",
                        mime="application/json"
                    )
                else:
                    st.warning("Excelå¯¼å‡ºæš‚æœªå®ç°")
                
                # é¢„è§ˆæ•°æ®
                st.subheader("ğŸ“‹ æ•°æ®é¢„è§ˆ")
                st.dataframe(df.head(100), use_container_width=True)
                st.info(f"å…± {len(df)} æ¡è®°å½•")
            else:
                st.warning("æŸ¥è¯¢ç»“æœä¸ºç©º")
                
        except Exception as e:
            st.error(f"æ•°æ®å¯¼å‡ºå¤±è´¥: {e}")


def render_data_management_main():
    """æ¸²æŸ“æ•°æ®ç®¡ç†ä¸»é¢æ¿"""
    # æ•°æ®æ¦‚è§ˆ
    render_data_overview()
    st.markdown("---")
    
    # åˆ›å»ºæ ‡ç­¾é¡µ
    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ”„ æ•°æ®æ›´æ–°", "ğŸ¯ è‚¡ç¥¨é€‰æ‹©", "ğŸ“¤ æ•°æ®å¯¼å‡º", "ğŸ“Š æ•°æ®è´¨é‡"])
    
    with tab1:
        render_data_update()
    
    with tab2:
        selected_stocks = render_stock_selector()
        # å°†é€‰ä¸­çš„è‚¡ç¥¨å­˜å‚¨åˆ°session state
        if selected_stocks:
            st.session_state['selected_stocks'] = selected_stocks
    
    with tab3:
        render_data_export()
    
    with tab4:
        st.header("ğŸ“Š æ•°æ®è´¨é‡ç›‘æ§")
        st.info("æ•°æ®è´¨é‡ç›‘æ§åŠŸèƒ½å¼€å‘ä¸­...")
        
        # å¯ä»¥æ·»åŠ æ•°æ®è´¨é‡æ£€æŸ¥ï¼Œå¦‚ï¼š
        # - ç¼ºå¤±æ•°æ®æ£€æŸ¥
        # - å¼‚å¸¸å€¼æ£€æŸ¥  
        # - æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥
        # - æ›´æ–°é¢‘ç‡æ£€æŸ¥
