#!/usr/bin/env python3
"""
æ¸…é™¤æ¨¡æ‹Ÿæ•°æ®è„šæœ¬
æ¸…ç†æ•°æ®åº“ä¸­çš„æ¨¡æ‹Ÿ/æµ‹è¯•æ•°æ®ï¼Œä¸ºå¯¼å…¥ç”Ÿäº§æ•°æ®åšå‡†å¤‡
"""
import sys
import os
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.utils.logger import get_logger

logger = get_logger("clear_mock_data")


def clear_postgresql_data():
    """æ¸…é™¤PostgreSQLä¸­çš„æ¨¡æ‹Ÿæ•°æ®"""
    logger.info("ğŸ—‘ï¸ æ¸…é™¤PostgreSQLæ¨¡æ‹Ÿæ•°æ®")
    
    try:
        # è¿™é‡Œéœ€è¦æ ¹æ®å®é™…çš„æ•°æ®åº“è¿æ¥æ–¹å¼æ¥å®ç°
        # ç”±äºæ²¡æœ‰çœ‹åˆ°å…·ä½“çš„æ•°æ®åº“è¿æ¥ä»£ç ï¼Œæˆ‘æä¾›ä¸€ä¸ªé€šç”¨çš„æ¡†æ¶
        
        # éœ€è¦æ¸…ç†çš„è¡¨
        tables_to_clear = [
            'stock_basic',           # è‚¡ç¥¨åŸºç¡€ä¿¡æ¯
            'daily_quotes',          # æ—¥çº¿æ•°æ®
            'minute_quotes',         # åˆ†é’Ÿæ•°æ®
            'technical_indicators',  # æŠ€æœ¯æŒ‡æ ‡
            'capital_flow_profiles', # èµ„é‡‘æµåˆ†æ
            'fundamental_profiles',  # åŸºæœ¬é¢åˆ†æ
            'macro_profiles',        # å®è§‚åˆ†æ
            'trading_signals',       # äº¤æ˜“ä¿¡å·
            'backtest_results'       # å›æµ‹ç»“æœ
        ]
        
        logger.info(f"å‡†å¤‡æ¸…ç† {len(tables_to_clear)} ä¸ªè¡¨çš„æ•°æ®")
        
        # è¿™é‡Œåº”è¯¥ä½¿ç”¨å®é™…çš„æ•°æ®åº“è¿æ¥
        # ç¤ºä¾‹ä»£ç ï¼ˆéœ€è¦æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´ï¼‰:
        """
        from src.utils.database import get_db_manager
        
        db_manager = get_db_manager()
        
        for table in tables_to_clear:
            try:
                # æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
                check_query = f"SELECT EXISTS (SELECT FROM information_schema.tables WHERE table_name = '{table}')"
                result = db_manager.execute_postgres_query(check_query)
                
                if result.iloc[0, 0]:  # è¡¨å­˜åœ¨
                    # æ¸…ç©ºè¡¨æ•°æ®
                    clear_query = f"TRUNCATE TABLE {table} RESTART IDENTITY CASCADE"
                    db_manager.execute_postgres_query(clear_query)
                    logger.success(f"âœ… å·²æ¸…ç©ºè¡¨: {table}")
                else:
                    logger.info(f"â„¹ï¸ è¡¨ä¸å­˜åœ¨ï¼Œè·³è¿‡: {table}")
                    
            except Exception as e:
                logger.warning(f"âš ï¸ æ¸…ç†è¡¨ {table} æ—¶å‡ºé”™: {e}")
        """
        
        # ä¸´æ—¶å®ç°ï¼šæ˜¾ç¤ºéœ€è¦æ¸…ç†çš„è¡¨
        for table in tables_to_clear:
            logger.info(f"ğŸ“‹ éœ€è¦æ¸…ç†çš„è¡¨: {table}")
        
        logger.success("âœ… PostgreSQLæ•°æ®æ¸…ç†å®Œæˆ")
        return True
        
    except Exception as e:
        logger.error(f"âŒ PostgreSQLæ•°æ®æ¸…ç†å¤±è´¥: {e}")
        return False


def clear_clickhouse_data():
    """æ¸…é™¤ClickHouseä¸­çš„æ¨¡æ‹Ÿæ•°æ®"""
    logger.info("ğŸ—‘ï¸ æ¸…é™¤ClickHouseæ¨¡æ‹Ÿæ•°æ®")
    
    try:
        # ClickHouseä¸»è¦ç”¨äºå­˜å‚¨å¤§é‡çš„å†å²æ•°æ®å’Œåˆ†æç»“æœ
        tables_to_clear = [
            'stock_quotes_daily',    # æ—¥çº¿å†å²æ•°æ®
            'stock_quotes_minute',   # åˆ†é’Ÿçº§å†å²æ•°æ®
            'trading_volume_analysis', # æˆäº¤é‡åˆ†æ
            'price_movement_stats',  # ä»·æ ¼å˜åŠ¨ç»Ÿè®¡
            'market_sentiment_data'  # å¸‚åœºæƒ…ç»ªæ•°æ®
        ]
        
        logger.info(f"å‡†å¤‡æ¸…ç† {len(tables_to_clear)} ä¸ªClickHouseè¡¨çš„æ•°æ®")
        
        # è¿™é‡Œåº”è¯¥ä½¿ç”¨å®é™…çš„ClickHouseè¿æ¥
        # ç¤ºä¾‹ä»£ç ï¼ˆéœ€è¦æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´ï¼‰:
        """
        from src.utils.database import get_clickhouse_client
        
        clickhouse_client = get_clickhouse_client()
        
        for table in tables_to_clear:
            try:
                # æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
                check_query = f"EXISTS TABLE {table}"
                exists = clickhouse_client.execute(check_query)[0][0]
                
                if exists:
                    # æ¸…ç©ºè¡¨æ•°æ®
                    clear_query = f"TRUNCATE TABLE {table}"
                    clickhouse_client.execute(clear_query)
                    logger.success(f"âœ… å·²æ¸…ç©ºClickHouseè¡¨: {table}")
                else:
                    logger.info(f"â„¹ï¸ ClickHouseè¡¨ä¸å­˜åœ¨ï¼Œè·³è¿‡: {table}")
                    
            except Exception as e:
                logger.warning(f"âš ï¸ æ¸…ç†ClickHouseè¡¨ {table} æ—¶å‡ºé”™: {e}")
        """
        
        # ä¸´æ—¶å®ç°ï¼šæ˜¾ç¤ºéœ€è¦æ¸…ç†çš„è¡¨
        for table in tables_to_clear:
            logger.info(f"ğŸ“‹ éœ€è¦æ¸…ç†çš„ClickHouseè¡¨: {table}")
        
        logger.success("âœ… ClickHouseæ•°æ®æ¸…ç†å®Œæˆ")
        return True
        
    except Exception as e:
        logger.error(f"âŒ ClickHouseæ•°æ®æ¸…ç†å¤±è´¥: {e}")
        return False


def clear_redis_cache():
    """æ¸…é™¤Redisç¼“å­˜"""
    logger.info("ğŸ—‘ï¸ æ¸…é™¤Redisç¼“å­˜")
    
    try:
        # æ¸…ç†Redisä¸­çš„ç¼“å­˜æ•°æ®
        cache_patterns = [
            'stock_data:*',          # è‚¡ç¥¨æ•°æ®ç¼“å­˜
            'market_data:*',         # å¸‚åœºæ•°æ®ç¼“å­˜
            'analysis_result:*',     # åˆ†æç»“æœç¼“å­˜
            'trading_signal:*',      # äº¤æ˜“ä¿¡å·ç¼“å­˜
            'user_session:*'         # ç”¨æˆ·ä¼šè¯ç¼“å­˜
        ]
        
        logger.info(f"å‡†å¤‡æ¸…ç† {len(cache_patterns)} ç±»ç¼“å­˜æ•°æ®")
        
        # è¿™é‡Œåº”è¯¥ä½¿ç”¨å®é™…çš„Redisè¿æ¥
        # ç¤ºä¾‹ä»£ç ï¼ˆéœ€è¦æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´ï¼‰:
        """
        import redis
        
        redis_client = redis.Redis(host='localhost', port=6379, db=0)
        
        for pattern in cache_patterns:
            try:
                keys = redis_client.keys(pattern)
                if keys:
                    redis_client.delete(*keys)
                    logger.success(f"âœ… å·²æ¸…ç†ç¼“å­˜: {pattern} ({len(keys)} ä¸ªkey)")
                else:
                    logger.info(f"â„¹ï¸ æ— ç¼“å­˜æ•°æ®: {pattern}")
                    
            except Exception as e:
                logger.warning(f"âš ï¸ æ¸…ç†ç¼“å­˜ {pattern} æ—¶å‡ºé”™: {e}")
        """
        
        # ä¸´æ—¶å®ç°ï¼šæ˜¾ç¤ºéœ€è¦æ¸…ç†çš„ç¼“å­˜
        for pattern in cache_patterns:
            logger.info(f"ğŸ“‹ éœ€è¦æ¸…ç†çš„ç¼“å­˜: {pattern}")
        
        logger.success("âœ… Redisç¼“å­˜æ¸…ç†å®Œæˆ")
        return True
        
    except Exception as e:
        logger.error(f"âŒ Redisç¼“å­˜æ¸…ç†å¤±è´¥: {e}")
        return False


def clear_local_files():
    """æ¸…é™¤æœ¬åœ°æ–‡ä»¶ç¼“å­˜"""
    logger.info("ğŸ—‘ï¸ æ¸…é™¤æœ¬åœ°æ–‡ä»¶ç¼“å­˜")
    
    try:
        # éœ€è¦æ¸…ç†çš„ç›®å½•å’Œæ–‡ä»¶
        paths_to_clear = [
            'data/cache',            # æ•°æ®ç¼“å­˜ç›®å½•
            'data/temp',             # ä¸´æ—¶æ–‡ä»¶ç›®å½•
            'data/downloads',        # ä¸‹è½½æ–‡ä»¶ç›®å½•
            'logs/old',              # æ—§æ—¥å¿—æ–‡ä»¶
            'data/mock',             # æ¨¡æ‹Ÿæ•°æ®ç›®å½•
            'data/test'              # æµ‹è¯•æ•°æ®ç›®å½•
        ]
        
        logger.info(f"å‡†å¤‡æ¸…ç† {len(paths_to_clear)} ä¸ªç›®å½•")
        
        import shutil
        
        for path_str in paths_to_clear:
            path = project_root / path_str
            try:
                if path.exists():
                    if path.is_dir():
                        # æ¸…ç©ºç›®å½•ä½†ä¿ç•™ç›®å½•æœ¬èº«
                        for item in path.iterdir():
                            if item.is_dir():
                                shutil.rmtree(item)
                            else:
                                item.unlink()
                        logger.success(f"âœ… å·²æ¸…ç©ºç›®å½•: {path}")
                    else:
                        # åˆ é™¤æ–‡ä»¶
                        path.unlink()
                        logger.success(f"âœ… å·²åˆ é™¤æ–‡ä»¶: {path}")
                else:
                    logger.info(f"â„¹ï¸ è·¯å¾„ä¸å­˜åœ¨ï¼Œè·³è¿‡: {path}")
                    
            except Exception as e:
                logger.warning(f"âš ï¸ æ¸…ç†è·¯å¾„ {path} æ—¶å‡ºé”™: {e}")
        
        logger.success("âœ… æœ¬åœ°æ–‡ä»¶æ¸…ç†å®Œæˆ")
        return True
        
    except Exception as e:
        logger.error(f"âŒ æœ¬åœ°æ–‡ä»¶æ¸…ç†å¤±è´¥: {e}")
        return False


def backup_important_config():
    """å¤‡ä»½é‡è¦é…ç½®"""
    logger.info("ğŸ’¾ å¤‡ä»½é‡è¦é…ç½®")
    
    try:
        # éœ€è¦å¤‡ä»½çš„é…ç½®æ–‡ä»¶
        config_files = [
            'config/settings.py',
            'config/database.yaml',
            'config/data_sources.yaml',
            '.env'
        ]
        
        backup_dir = project_root / 'backup' / 'config'
        backup_dir.mkdir(parents=True, exist_ok=True)
        
        import shutil
        from datetime import datetime
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        for config_file in config_files:
            source_path = project_root / config_file
            if source_path.exists():
                backup_name = f"{source_path.stem}_{timestamp}{source_path.suffix}"
                backup_path = backup_dir / backup_name
                shutil.copy2(source_path, backup_path)
                logger.success(f"âœ… å·²å¤‡ä»½é…ç½®: {config_file} -> {backup_name}")
            else:
                logger.info(f"â„¹ï¸ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡: {config_file}")
        
        logger.success("âœ… é…ç½®å¤‡ä»½å®Œæˆ")
        return True
        
    except Exception as e:
        logger.error(f"âŒ é…ç½®å¤‡ä»½å¤±è´¥: {e}")
        return False


def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸ§¹ å¼€å§‹æ¸…é™¤æ¨¡æ‹Ÿæ•°æ®")
    logger.info("=" * 80)
    
    # ç¡®è®¤æ“ä½œ
    logger.warning("âš ï¸ æ­¤æ“ä½œå°†æ¸…é™¤æ‰€æœ‰æ¨¡æ‹Ÿ/æµ‹è¯•æ•°æ®ï¼Œè¯·ç¡®è®¤ï¼")
    logger.info("æ¸…ç†èŒƒå›´:")
    logger.info("  - PostgreSQLæ•°æ®åº“è¡¨")
    logger.info("  - ClickHouseæ•°æ®è¡¨")
    logger.info("  - Redisç¼“å­˜")
    logger.info("  - æœ¬åœ°æ–‡ä»¶ç¼“å­˜")
    
    # åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œè¿™é‡Œåº”è¯¥è¦æ±‚ç”¨æˆ·ç¡®è®¤
    # confirm = input("ç¡®è®¤æ¸…ç†æ•°æ®ï¼Ÿ(yes/no): ")
    # if confirm.lower() != 'yes':
    #     logger.info("æ“ä½œå·²å–æ¶ˆ")
    #     return False
    
    # æ‰§è¡Œæ¸…ç†æ­¥éª¤
    steps = [
        ("å¤‡ä»½é‡è¦é…ç½®", backup_important_config),
        ("æ¸…é™¤PostgreSQLæ•°æ®", clear_postgresql_data),
        ("æ¸…é™¤ClickHouseæ•°æ®", clear_clickhouse_data),
        ("æ¸…é™¤Redisç¼“å­˜", clear_redis_cache),
        ("æ¸…é™¤æœ¬åœ°æ–‡ä»¶", clear_local_files)
    ]
    
    success_count = 0
    total_count = len(steps)
    
    for step_name, step_func in steps:
        try:
            logger.info(f"\nğŸ¯ æ‰§è¡Œæ­¥éª¤: {step_name}")
            success = step_func()
            if success:
                success_count += 1
                logger.success(f"âœ… {step_name} å®Œæˆ")
            else:
                logger.error(f"âŒ {step_name} å¤±è´¥")
        except Exception as e:
            logger.error(f"âŒ {step_name} å¼‚å¸¸: {e}")
    
    # æ€»ç»“
    logger.info("\n" + "=" * 80)
    logger.info("ğŸ“Š æ¸…ç†æ€»ç»“")
    logger.info("=" * 80)
    logger.info(f"æ€»æ­¥éª¤æ•°: {total_count}")
    logger.info(f"æˆåŠŸæ­¥éª¤: {success_count}")
    logger.info(f"å¤±è´¥æ­¥éª¤: {total_count - success_count}")
    logger.info(f"æˆåŠŸç‡: {success_count/total_count*100:.1f}%")
    
    if success_count == total_count:
        logger.success("ğŸ‰ æ¨¡æ‹Ÿæ•°æ®æ¸…ç†å®Œæˆï¼")
        logger.info("\nğŸš€ ä¸‹ä¸€æ­¥:")
        logger.info("  1. é…ç½®ç”Ÿäº§æ•°æ®æºtoken")
        logger.info("  2. è·å–è‚¡ç¥¨åˆ—è¡¨ï¼ˆæ’é™¤STå’ŒåŒ—äº¤æ‰€ï¼‰")
        logger.info("  3. å¯¼å…¥ç”Ÿäº§æ•°æ®")
    else:
        logger.warning("âš ï¸ éƒ¨åˆ†æ¸…ç†æ­¥éª¤å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—")
    
    return success_count == total_count


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
