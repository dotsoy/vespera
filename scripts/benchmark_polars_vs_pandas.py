#!/usr/bin/env python3
"""
Polars vs Pandas æ€§èƒ½åŸºå‡†æµ‹è¯•
"""
import sys
import time
import psutil
import numpy as np
import pandas as pd
from pathlib import Path
from typing import Dict, Any, Callable
import warnings
warnings.filterwarnings('ignore')

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.utils.logger import get_logger

logger = get_logger("benchmark")

# å°è¯•å¯¼å…¥ Polars
try:
    import polars as pl
    POLARS_AVAILABLE = True
    logger.info("âœ… Polars å¯ç”¨")
except ImportError:
    POLARS_AVAILABLE = False
    logger.warning("âš ï¸ Polars æœªå®‰è£…ï¼Œå°†è·³è¿‡ Polars æµ‹è¯•")


def generate_test_data(n_stocks: int = 1000, n_days: int = 250) -> pd.DataFrame:
    """ç”Ÿæˆæµ‹è¯•æ•°æ®"""
    logger.info(f"ç”Ÿæˆæµ‹è¯•æ•°æ®: {n_stocks} åªè‚¡ç¥¨ Ã— {n_days} å¤©")
    
    np.random.seed(42)
    data = []
    
    for i in range(n_stocks):
        ts_code = f"{str(i+1).zfill(6)}.SZ"
        
        # ç”Ÿæˆä»·æ ¼æ•°æ®
        base_price = np.random.uniform(10, 100)
        price_changes = np.random.normal(0, 0.02, n_days)
        prices = [base_price]
        
        for change in price_changes[1:]:
            new_price = prices[-1] * (1 + change)
            prices.append(max(new_price, 1.0))  # ä»·æ ¼ä¸èƒ½ä¸ºè´Ÿ
        
        for day in range(n_days):
            open_price = prices[day] * np.random.uniform(0.98, 1.02)
            high_price = max(open_price, prices[day]) * np.random.uniform(1.0, 1.05)
            low_price = min(open_price, prices[day]) * np.random.uniform(0.95, 1.0)
            close_price = prices[day]
            volume = np.random.randint(1000000, 100000000)
            
            data.append({
                'ts_code': ts_code,
                'trade_date': f"2024-{(day % 12) + 1:02d}-{(day % 28) + 1:02d}",
                'open_price': round(open_price, 2),
                'high_price': round(high_price, 2),
                'low_price': round(low_price, 2),
                'close_price': round(close_price, 2),
                'vol': volume,
                'pct_chg': round(price_changes[day] * 100, 2)
            })
    
    df = pd.DataFrame(data)
    logger.info(f"æµ‹è¯•æ•°æ®ç”Ÿæˆå®Œæˆ: {len(df)} æ¡è®°å½•")
    return df


def measure_performance(func: Callable, *args, **kwargs) -> Dict[str, Any]:
    """æµ‹é‡å‡½æ•°æ€§èƒ½"""
    # è·å–åˆå§‹å†…å­˜ä½¿ç”¨
    process = psutil.Process()
    initial_memory = process.memory_info().rss / 1024 / 1024  # MB
    
    # æ‰§è¡Œå‡½æ•°å¹¶æµ‹é‡æ—¶é—´
    start_time = time.time()
    result = func(*args, **kwargs)
    end_time = time.time()
    
    # è·å–å³°å€¼å†…å­˜ä½¿ç”¨
    peak_memory = process.memory_info().rss / 1024 / 1024  # MB
    memory_used = peak_memory - initial_memory
    
    return {
        'execution_time': end_time - start_time,
        'memory_used': max(0, memory_used),
        'result_size': len(result) if hasattr(result, '__len__') else 0
    }


def benchmark_technical_indicators_pandas(df: pd.DataFrame) -> pd.DataFrame:
    """Pandas æŠ€æœ¯æŒ‡æ ‡è®¡ç®—åŸºå‡†"""
    logger.info("ğŸ¼ Pandas æŠ€æœ¯æŒ‡æ ‡è®¡ç®—...")
    
    # æŒ‰è‚¡ç¥¨åˆ†ç»„è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
    def calculate_indicators_for_stock(group):
        group = group.sort_values('trade_date').copy()
        
        # ç§»åŠ¨å¹³å‡
        group['ma_5'] = group['close_price'].rolling(5, min_periods=1).mean()
        group['ma_20'] = group['close_price'].rolling(20, min_periods=1).mean()
        
        # ç®€å• RSI è®¡ç®—
        delta = group['close_price'].diff()
        gain = (delta.where(delta > 0, 0)).rolling(14, min_periods=1).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(14, min_periods=1).mean()
        rs = gain / loss.replace(0, np.inf)
        group['rsi'] = 100 - (100 / (1 + rs))
        
        # æˆäº¤é‡æ¯”ç‡
        group['vol_ma'] = group['vol'].rolling(20, min_periods=1).mean()
        group['vol_ratio'] = group['vol'] / group['vol_ma']
        
        return group
    
    result = df.groupby('ts_code').apply(calculate_indicators_for_stock)
    return result.reset_index(drop=True)


def benchmark_technical_indicators_polars(df: pd.DataFrame) -> pd.DataFrame:
    """Polars æŠ€æœ¯æŒ‡æ ‡è®¡ç®—åŸºå‡†"""
    if not POLARS_AVAILABLE:
        return df
    
    logger.info("âš¡ Polars æŠ€æœ¯æŒ‡æ ‡è®¡ç®—...")
    
    # è½¬æ¢ä¸º Polars DataFrame
    pl_df = pl.from_pandas(df)
    
    # ä½¿ç”¨ Polars é«˜æ•ˆè®¡ç®—
    result = pl_df.sort(['ts_code', 'trade_date']).with_columns([
        # ç§»åŠ¨å¹³å‡
        pl.col('close_price').rolling_mean(5).over('ts_code').alias('ma_5'),
        pl.col('close_price').rolling_mean(20).over('ts_code').alias('ma_20'),
        
        # æˆäº¤é‡æ¯”ç‡
        pl.col('vol').rolling_mean(20).over('ts_code').alias('vol_ma'),
    ]).with_columns([
        (pl.col('vol') / pl.col('vol_ma')).alias('vol_ratio'),
        
        # ç®€åŒ–çš„ RSI è®¡ç®—
        (pl.col('close_price').diff().over('ts_code')).alias('price_diff')
    ]).with_columns([
        pl.when(pl.col('price_diff') > 0)
        .then(pl.col('price_diff'))
        .otherwise(0)
        .rolling_mean(14).over('ts_code').alias('gain'),
        
        pl.when(pl.col('price_diff') < 0)
        .then(-pl.col('price_diff'))
        .otherwise(0)
        .rolling_mean(14).over('ts_code').alias('loss')
    ]).with_columns([
        (100 - (100 / (1 + pl.col('gain') / pl.col('loss')))).alias('rsi')
    ]).drop(['price_diff', 'gain', 'loss'])
    
    return result.to_pandas()


def benchmark_aggregation_pandas(df: pd.DataFrame) -> pd.DataFrame:
    """Pandas èšåˆæ“ä½œåŸºå‡†"""
    logger.info("ğŸ¼ Pandas èšåˆæ“ä½œ...")
    
    # å¤æ‚èšåˆæ“ä½œ
    result = df.groupby('ts_code').agg({
        'close_price': ['mean', 'std', 'min', 'max'],
        'vol': ['sum', 'mean'],
        'pct_chg': ['mean', 'std']
    }).reset_index()
    
    # å±•å¹³åˆ—å
    result.columns = ['_'.join(col).strip() if col[1] else col[0] for col in result.columns]
    
    return result


def benchmark_aggregation_polars(df: pd.DataFrame) -> pd.DataFrame:
    """Polars èšåˆæ“ä½œåŸºå‡†"""
    if not POLARS_AVAILABLE:
        return df
    
    logger.info("âš¡ Polars èšåˆæ“ä½œ...")
    
    pl_df = pl.from_pandas(df)
    
    result = pl_df.group_by('ts_code').agg([
        pl.col('close_price').mean().alias('close_price_mean'),
        pl.col('close_price').std().alias('close_price_std'),
        pl.col('close_price').min().alias('close_price_min'),
        pl.col('close_price').max().alias('close_price_max'),
        pl.col('vol').sum().alias('vol_sum'),
        pl.col('vol').mean().alias('vol_mean'),
        pl.col('pct_chg').mean().alias('pct_chg_mean'),
        pl.col('pct_chg').std().alias('pct_chg_std')
    ])
    
    return result.to_pandas()


def benchmark_filtering_pandas(df: pd.DataFrame) -> pd.DataFrame:
    """Pandas è¿‡æ»¤æ“ä½œåŸºå‡†"""
    logger.info("ğŸ¼ Pandas è¿‡æ»¤æ“ä½œ...")
    
    # å¤æ‚è¿‡æ»¤æ¡ä»¶
    result = df[
        (df['close_price'] > 20) & 
        (df['close_price'] < 80) &
        (df['vol'] > 5000000) &
        (df['pct_chg'].abs() < 5)
    ].copy()
    
    return result


def benchmark_filtering_polars(df: pd.DataFrame) -> pd.DataFrame:
    """Polars è¿‡æ»¤æ“ä½œåŸºå‡†"""
    if not POLARS_AVAILABLE:
        return df
    
    logger.info("âš¡ Polars è¿‡æ»¤æ“ä½œ...")
    
    pl_df = pl.from_pandas(df)
    
    result = pl_df.filter(
        (pl.col('close_price') > 20) & 
        (pl.col('close_price') < 80) &
        (pl.col('vol') > 5000000) &
        (pl.col('pct_chg').abs() < 5)
    )
    
    return result.to_pandas()


def run_benchmark_suite():
    """è¿è¡Œå®Œæ•´åŸºå‡†æµ‹è¯•å¥—ä»¶"""
    logger.info("=" * 60)
    logger.info("ğŸš€ Polars vs Pandas æ€§èƒ½åŸºå‡†æµ‹è¯•")
    logger.info("=" * 60)
    
    # æµ‹è¯•ä¸åŒæ•°æ®è§„æ¨¡
    test_sizes = [
        (100, 30, "å°è§„æ¨¡"),    # 3K è®°å½•
        (500, 100, "ä¸­è§„æ¨¡"),   # 50K è®°å½•
        (1000, 250, "å¤§è§„æ¨¡")   # 250K è®°å½•
    ]
    
    results = {}
    
    for n_stocks, n_days, size_name in test_sizes:
        logger.info(f"\nğŸ“Š {size_name}æµ‹è¯• ({n_stocks} è‚¡ç¥¨ Ã— {n_days} å¤©)")
        logger.info("-" * 40)
        
        # ç”Ÿæˆæµ‹è¯•æ•°æ®
        df = generate_test_data(n_stocks, n_days)
        
        # æµ‹è¯•æŠ€æœ¯æŒ‡æ ‡è®¡ç®—
        logger.info("ğŸ§® æŠ€æœ¯æŒ‡æ ‡è®¡ç®—æµ‹è¯•...")
        pandas_tech = measure_performance(benchmark_technical_indicators_pandas, df)
        
        if POLARS_AVAILABLE:
            polars_tech = measure_performance(benchmark_technical_indicators_polars, df)
            tech_speedup = pandas_tech['execution_time'] / polars_tech['execution_time']
            tech_memory_ratio = polars_tech['memory_used'] / max(pandas_tech['memory_used'], 1)
        else:
            polars_tech = {'execution_time': 0, 'memory_used': 0}
            tech_speedup = 0
            tech_memory_ratio = 0
        
        # æµ‹è¯•èšåˆæ“ä½œ
        logger.info("ğŸ“ˆ èšåˆæ“ä½œæµ‹è¯•...")
        pandas_agg = measure_performance(benchmark_aggregation_pandas, df)
        
        if POLARS_AVAILABLE:
            polars_agg = measure_performance(benchmark_aggregation_polars, df)
            agg_speedup = pandas_agg['execution_time'] / polars_agg['execution_time']
            agg_memory_ratio = polars_agg['memory_used'] / max(pandas_agg['memory_used'], 1)
        else:
            polars_agg = {'execution_time': 0, 'memory_used': 0}
            agg_speedup = 0
            agg_memory_ratio = 0
        
        # æµ‹è¯•è¿‡æ»¤æ“ä½œ
        logger.info("ğŸ” è¿‡æ»¤æ“ä½œæµ‹è¯•...")
        pandas_filter = measure_performance(benchmark_filtering_pandas, df)
        
        if POLARS_AVAILABLE:
            polars_filter = measure_performance(benchmark_filtering_polars, df)
            filter_speedup = pandas_filter['execution_time'] / polars_filter['execution_time']
            filter_memory_ratio = polars_filter['memory_used'] / max(pandas_filter['memory_used'], 1)
        else:
            polars_filter = {'execution_time': 0, 'memory_used': 0}
            filter_speedup = 0
            filter_memory_ratio = 0
        
        # ä¿å­˜ç»“æœ
        results[size_name] = {
            'data_size': len(df),
            'technical_indicators': {
                'pandas_time': pandas_tech['execution_time'],
                'polars_time': polars_tech['execution_time'],
                'speedup': tech_speedup,
                'memory_ratio': tech_memory_ratio
            },
            'aggregation': {
                'pandas_time': pandas_agg['execution_time'],
                'polars_time': polars_agg['execution_time'],
                'speedup': agg_speedup,
                'memory_ratio': agg_memory_ratio
            },
            'filtering': {
                'pandas_time': pandas_filter['execution_time'],
                'polars_time': polars_filter['execution_time'],
                'speedup': filter_speedup,
                'memory_ratio': filter_memory_ratio
            }
        }
        
        # è¾“å‡ºç»“æœ
        logger.info(f"ğŸ“Š {size_name}æµ‹è¯•ç»“æœ:")
        logger.info(f"  æ•°æ®è§„æ¨¡: {len(df):,} æ¡è®°å½•")
        
        if POLARS_AVAILABLE:
            logger.info(f"  æŠ€æœ¯æŒ‡æ ‡è®¡ç®—:")
            logger.info(f"    Pandas: {pandas_tech['execution_time']:.2f}s")
            logger.info(f"    Polars: {polars_tech['execution_time']:.2f}s")
            logger.info(f"    åŠ é€Ÿæ¯”: {tech_speedup:.1f}x")
            
            logger.info(f"  èšåˆæ“ä½œ:")
            logger.info(f"    Pandas: {pandas_agg['execution_time']:.2f}s")
            logger.info(f"    Polars: {polars_agg['execution_time']:.2f}s")
            logger.info(f"    åŠ é€Ÿæ¯”: {agg_speedup:.1f}x")
            
            logger.info(f"  è¿‡æ»¤æ“ä½œ:")
            logger.info(f"    Pandas: {pandas_filter['execution_time']:.2f}s")
            logger.info(f"    Polars: {polars_filter['execution_time']:.2f}s")
            logger.info(f"    åŠ é€Ÿæ¯”: {filter_speedup:.1f}x")
        else:
            logger.warning("  Polars æœªå®‰è£…ï¼Œè·³è¿‡æ€§èƒ½å¯¹æ¯”")
    
    # è¾“å‡ºæ€»ç»“
    logger.info("\n" + "=" * 60)
    logger.info("ğŸ“‹ åŸºå‡†æµ‹è¯•æ€»ç»“")
    logger.info("=" * 60)
    
    if POLARS_AVAILABLE:
        for size_name, result in results.items():
            logger.info(f"\n{size_name} ({result['data_size']:,} è®°å½•):")
            logger.info(f"  æŠ€æœ¯æŒ‡æ ‡: {result['technical_indicators']['speedup']:.1f}x åŠ é€Ÿ")
            logger.info(f"  èšåˆæ“ä½œ: {result['aggregation']['speedup']:.1f}x åŠ é€Ÿ")
            logger.info(f"  è¿‡æ»¤æ“ä½œ: {result['filtering']['speedup']:.1f}x åŠ é€Ÿ")
        
        # è®¡ç®—å¹³å‡åŠ é€Ÿæ¯”
        avg_tech_speedup = np.mean([r['technical_indicators']['speedup'] for r in results.values()])
        avg_agg_speedup = np.mean([r['aggregation']['speedup'] for r in results.values()])
        avg_filter_speedup = np.mean([r['filtering']['speedup'] for r in results.values()])
        
        logger.info(f"\nğŸ¯ å¹³å‡æ€§èƒ½æå‡:")
        logger.info(f"  æŠ€æœ¯æŒ‡æ ‡è®¡ç®—: {avg_tech_speedup:.1f}x")
        logger.info(f"  èšåˆæ“ä½œ: {avg_agg_speedup:.1f}x")
        logger.info(f"  è¿‡æ»¤æ“ä½œ: {avg_filter_speedup:.1f}x")
        
        if avg_tech_speedup > 2.0:
            logger.success("ğŸš€ Polars åœ¨æŠ€æœ¯æŒ‡æ ‡è®¡ç®—ä¸Šæœ‰æ˜¾è‘—ä¼˜åŠ¿ï¼")
        if avg_agg_speedup > 3.0:
            logger.success("ğŸš€ Polars åœ¨èšåˆæ“ä½œä¸Šæœ‰æ˜¾è‘—ä¼˜åŠ¿ï¼")
        
        logger.info(f"\nğŸ’¡ æ¨è:")
        if avg_tech_speedup > 1.5 or avg_agg_speedup > 2.0:
            logger.success("âœ… å¼ºçƒˆæ¨èè¿ç§»åˆ° Polarsï¼")
        else:
            logger.info("âš ï¸ æ€§èƒ½æå‡æœ‰é™ï¼Œéœ€è¦æƒè¡¡è¿ç§»æˆæœ¬")
    else:
        logger.warning("âŒ æ— æ³•è¿›è¡Œæ€§èƒ½å¯¹æ¯”ï¼Œè¯·å®‰è£… Polars: pip install polars")
    
    return results


if __name__ == "__main__":
    run_benchmark_suite()
