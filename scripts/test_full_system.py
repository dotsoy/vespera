#!/usr/bin/env python3
"""
å®Œæ•´ç³»ç»Ÿæµ‹è¯•è„šæœ¬
"""
import sys
import os
from pathlib import Path
import pandas as pd
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.utils.database import get_db_manager
from src.utils.logger import get_logger
from src.analyzers.technical_analyzer import TechnicalAnalyzer
from src.analyzers.capital_flow_analyzer import CapitalFlowAnalyzer
from src.analyzers.fundamental_analyzer import FundamentalAnalyzer
from src.analyzers.macro_analyzer import MacroAnalyzer
from src.fusion.signal_fusion_engine import SignalFusionEngine

logger = get_logger("test_full_system")


def test_database_connections():
    """æµ‹è¯•æ•°æ®åº“è¿žæŽ¥"""
    logger.info("ðŸ”— æµ‹è¯•æ•°æ®åº“è¿žæŽ¥...")
    
    try:
        db_manager = get_db_manager()
        results = db_manager.test_connections()
        
        all_connected = True
        for db_name, status in results.items():
            if status:
                logger.success(f"âœ… {db_name} è¿žæŽ¥æˆåŠŸ")
            else:
                logger.error(f"âŒ {db_name} è¿žæŽ¥å¤±è´¥")
                all_connected = False
        
        return all_connected
        
    except Exception as e:
        logger.error(f"æ•°æ®åº“è¿žæŽ¥æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_data_availability():
    """æµ‹è¯•æ•°æ®å¯ç”¨æ€§"""
    logger.info("ðŸ“Š æµ‹è¯•æ•°æ®å¯ç”¨æ€§...")
    
    try:
        db_manager = get_db_manager()
        
        # æ£€æŸ¥è‚¡ç¥¨åŸºç¡€ä¿¡æ¯
        stock_count = db_manager.execute_postgres_query("SELECT COUNT(*) as count FROM stock_basic")
        stock_num = stock_count.iloc[0]['count'] if not stock_count.empty else 0
        logger.info(f"è‚¡ç¥¨åŸºç¡€ä¿¡æ¯: {stock_num} æ¡")
        
        # æ£€æŸ¥æ—¥çº¿è¡Œæƒ…
        quotes_count = db_manager.execute_postgres_query("SELECT COUNT(*) as count FROM stock_daily_quotes")
        quotes_num = quotes_count.iloc[0]['count'] if not quotes_count.empty else 0
        logger.info(f"æ—¥çº¿è¡Œæƒ…æ•°æ®: {quotes_num} æ¡")
        
        # æ£€æŸ¥èµ„é‡‘æµæ•°æ®
        money_flow_count = db_manager.execute_postgres_query("SELECT COUNT(*) as count FROM money_flow_daily")
        money_flow_num = money_flow_count.iloc[0]['count'] if not money_flow_count.empty else 0
        logger.info(f"èµ„é‡‘æµæ•°æ®: {money_flow_num} æ¡")
        
        if stock_num > 0 and quotes_num > 0 and money_flow_num > 0:
            logger.success("âœ… åŸºç¡€æ•°æ®å®Œæ•´")
            return True
        else:
            logger.warning("âš ï¸ åŸºç¡€æ•°æ®ä¸å®Œæ•´ï¼Œå»ºè®®è¿è¡Œ fetch_sample_data.py")
            return False
            
    except Exception as e:
        logger.error(f"æ•°æ®å¯ç”¨æ€§æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_analyzers():
    """æµ‹è¯•å„åˆ†æžå™¨"""
    logger.info("ðŸ” æµ‹è¯•åˆ†æžå™¨...")
    
    try:
        db_manager = get_db_manager()
        
        # èŽ·å–ä¸€åªæµ‹è¯•è‚¡ç¥¨
        test_stock = db_manager.execute_postgres_query(
            "SELECT ts_code FROM stock_basic LIMIT 1"
        )
        
        if test_stock.empty:
            logger.error("æ²¡æœ‰å¯ç”¨çš„æµ‹è¯•è‚¡ç¥¨")
            return False
        
        ts_code = test_stock.iloc[0]['ts_code']
        trade_date = datetime.now().strftime('%Y-%m-%d')
        
        logger.info(f"ä½¿ç”¨æµ‹è¯•è‚¡ç¥¨: {ts_code}")
        
        # æµ‹è¯•æŠ€æœ¯åˆ†æžå™¨
        logger.info("æµ‹è¯•æŠ€æœ¯åˆ†æžå™¨...")
        tech_analyzer = TechnicalAnalyzer()
        tech_result = tech_analyzer.analyze_stock(ts_code, trade_date)
        if tech_result:
            logger.success("âœ… æŠ€æœ¯åˆ†æžå™¨æ­£å¸¸")
        else:
            logger.warning("âš ï¸ æŠ€æœ¯åˆ†æžå™¨è¿”å›žç©ºç»“æžœ")
        
        # æµ‹è¯•èµ„é‡‘æµåˆ†æžå™¨
        logger.info("æµ‹è¯•èµ„é‡‘æµåˆ†æžå™¨...")
        capital_analyzer = CapitalFlowAnalyzer()
        capital_result = capital_analyzer.analyze_stock(ts_code, trade_date)
        if capital_result:
            logger.success("âœ… èµ„é‡‘æµåˆ†æžå™¨æ­£å¸¸")
        else:
            logger.warning("âš ï¸ èµ„é‡‘æµåˆ†æžå™¨è¿”å›žç©ºç»“æžœ")
        
        # æµ‹è¯•åŸºæœ¬é¢åˆ†æžå™¨
        logger.info("æµ‹è¯•åŸºæœ¬é¢åˆ†æžå™¨...")
        fundamental_analyzer = FundamentalAnalyzer()
        fundamental_result = fundamental_analyzer.analyze_stock(ts_code, trade_date)
        if fundamental_result:
            logger.success("âœ… åŸºæœ¬é¢åˆ†æžå™¨æ­£å¸¸")
        else:
            logger.warning("âš ï¸ åŸºæœ¬é¢åˆ†æžå™¨è¿”å›žç©ºç»“æžœ")
        

        
        # æµ‹è¯•å®è§‚åˆ†æžå™¨
        logger.info("æµ‹è¯•å®è§‚åˆ†æžå™¨...")
        macro_analyzer = MacroAnalyzer()
        macro_result = macro_analyzer.analyze_macro_environment(trade_date)
        if macro_result:
            logger.success("âœ… å®è§‚åˆ†æžå™¨æ­£å¸¸")
        else:
            logger.warning("âš ï¸ å®è§‚åˆ†æžå™¨è¿”å›žç©ºç»“æžœ")
        
        return True
        
    except Exception as e:
        logger.error(f"åˆ†æžå™¨æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_signal_fusion():
    """æµ‹è¯•ä¿¡å·èžåˆå¼•æ“Ž"""
    logger.info("ðŸŽ¯ æµ‹è¯•ä¿¡å·èžåˆå¼•æ“Ž...")
    
    try:
        db_manager = get_db_manager()
        
        # èŽ·å–æµ‹è¯•è‚¡ç¥¨
        test_stocks = db_manager.execute_postgres_query(
            "SELECT ts_code FROM stock_basic LIMIT 3"
        )
        
        if test_stocks.empty:
            logger.error("æ²¡æœ‰å¯ç”¨çš„æµ‹è¯•è‚¡ç¥¨")
            return False
        
        trade_date = datetime.now().strftime('%Y-%m-%d')
        fusion_engine = SignalFusionEngine()
        
        signals_generated = 0
        
        for _, row in test_stocks.iterrows():
            ts_code = row['ts_code']
            logger.info(f"æµ‹è¯•è‚¡ç¥¨ {ts_code} çš„ä¿¡å·ç”Ÿæˆ...")
            
            signal = fusion_engine.analyze_and_generate_signal(ts_code, trade_date)
            
            if signal:
                logger.success(f"âœ… ä¸ºè‚¡ç¥¨ {ts_code} ç”Ÿæˆä¿¡å·ï¼Œç½®ä¿¡åº¦: {signal['confidence_score']:.3f}")
                signals_generated += 1
            else:
                logger.info(f"â„¹ï¸ è‚¡ç¥¨ {ts_code} æœªé€šè¿‡èžåˆé€»è¾‘ç­›é€‰")
        
        logger.info(f"å…±ç”Ÿæˆ {signals_generated} ä¸ªä¿¡å·")
        
        if signals_generated > 0:
            logger.success("âœ… ä¿¡å·èžåˆå¼•æ“Žæ­£å¸¸å·¥ä½œ")
        else:
            logger.warning("âš ï¸ ä¿¡å·èžåˆå¼•æ“Žæœªç”Ÿæˆä»»ä½•ä¿¡å·ï¼ˆå¯èƒ½æ˜¯æ­£å¸¸çš„ï¼‰")
        
        return True
        
    except Exception as e:
        logger.error(f"ä¿¡å·èžåˆæµ‹è¯•å¤±è´¥: {e}")
        return False


def test_data_pipeline():
    """æµ‹è¯•å®Œæ•´æ•°æ®å¤„ç†æµç¨‹"""
    logger.info("ðŸ”„ æµ‹è¯•å®Œæ•´æ•°æ®å¤„ç†æµç¨‹...")
    
    try:
        db_manager = get_db_manager()
        trade_date = datetime.now().strftime('%Y-%m-%d')
        
        # èŽ·å–è‚¡ç¥¨åˆ—è¡¨
        stocks = db_manager.execute_postgres_query("SELECT ts_code FROM stock_basic LIMIT 5")
        
        if stocks.empty:
            logger.error("æ²¡æœ‰å¯ç”¨çš„è‚¡ç¥¨æ•°æ®")
            return False
        
        # åˆå§‹åŒ–åˆ†æžå™¨
        tech_analyzer = TechnicalAnalyzer()
        capital_analyzer = CapitalFlowAnalyzer()
        
        tech_results = []
        capital_results = []
        
        # æ‰¹é‡åˆ†æž
        for _, row in stocks.iterrows():
            ts_code = row['ts_code']
            
            # æŠ€æœ¯åˆ†æž
            tech_result = tech_analyzer.analyze_stock(ts_code, trade_date)
            if tech_result:
                tech_results.append(tech_result)
            
            # èµ„é‡‘æµåˆ†æž
            capital_result = capital_analyzer.analyze_stock(ts_code, trade_date)
            if capital_result:
                capital_results.append(capital_result)
        
        # ä¿å­˜åˆ†æžç»“æžœ
        if tech_results:
            tech_df = pd.DataFrame(tech_results)
            db_manager.insert_dataframe_to_postgres(
                tech_df, 'technical_daily_profiles', if_exists='append'
            )
            logger.success(f"âœ… æŠ€æœ¯åˆ†æžç»“æžœå·²ä¿å­˜: {len(tech_results)} æ¡")
        
        if capital_results:
            capital_df = pd.DataFrame(capital_results)
            db_manager.insert_dataframe_to_postgres(
                capital_df, 'capital_flow_profiles', if_exists='append'
            )
            logger.success(f"âœ… èµ„é‡‘æµåˆ†æžç»“æžœå·²ä¿å­˜: {len(capital_results)} æ¡")
        
        return True
        
    except Exception as e:
        logger.error(f"æ•°æ®å¤„ç†æµç¨‹æµ‹è¯•å¤±è´¥: {e}")
        return False


def main():
    """ä¸»å‡½æ•°"""
    logger.info("=" * 60)
    logger.info("ðŸŒŸ å¯æ˜Žæ˜Ÿç³»ç»Ÿå®Œæ•´æµ‹è¯•å¼€å§‹")
    logger.info("=" * 60)
    
    test_results = []
    
    # 1. æµ‹è¯•æ•°æ®åº“è¿žæŽ¥
    test_results.append(("æ•°æ®åº“è¿žæŽ¥", test_database_connections()))
    
    # 2. æµ‹è¯•æ•°æ®å¯ç”¨æ€§
    test_results.append(("æ•°æ®å¯ç”¨æ€§", test_data_availability()))
    
    # 3. æµ‹è¯•åˆ†æžå™¨
    test_results.append(("åˆ†æžå™¨åŠŸèƒ½", test_analyzers()))
    
    # 4. æµ‹è¯•ä¿¡å·èžåˆ
    test_results.append(("ä¿¡å·èžåˆ", test_signal_fusion()))
    
    # 5. æµ‹è¯•æ•°æ®å¤„ç†æµç¨‹
    test_results.append(("æ•°æ®å¤„ç†æµç¨‹", test_data_pipeline()))
    
    # æ±‡æ€»æµ‹è¯•ç»“æžœ
    logger.info("=" * 60)
    logger.info("ðŸ“Š æµ‹è¯•ç»“æžœæ±‡æ€»")
    logger.info("=" * 60)
    
    passed_tests = 0
    total_tests = len(test_results)
    
    for test_name, result in test_results:
        if result:
            logger.success(f"âœ… {test_name}: é€šè¿‡")
            passed_tests += 1
        else:
            logger.error(f"âŒ {test_name}: å¤±è´¥")
    
    success_rate = passed_tests / total_tests
    
    logger.info("=" * 60)
    if success_rate >= 0.8:
        logger.success(f"ðŸŽ‰ ç³»ç»Ÿæµ‹è¯•å®Œæˆï¼é€šè¿‡çŽ‡: {success_rate:.1%} ({passed_tests}/{total_tests})")
        logger.success("ç³»ç»Ÿè¿è¡Œæ­£å¸¸ï¼Œå¯ä»¥å¼€å§‹ä½¿ç”¨ï¼")
    elif success_rate >= 0.6:
        logger.warning(f"âš ï¸ ç³»ç»Ÿæµ‹è¯•å®Œæˆï¼é€šè¿‡çŽ‡: {success_rate:.1%} ({passed_tests}/{total_tests})")
        logger.warning("ç³»ç»ŸåŸºæœ¬å¯ç”¨ï¼Œä½†å»ºè®®æ£€æŸ¥å¤±è´¥çš„æµ‹è¯•é¡¹")
    else:
        logger.error(f"ðŸš¨ ç³»ç»Ÿæµ‹è¯•å®Œæˆï¼é€šè¿‡çŽ‡: {success_rate:.1%} ({passed_tests}/{total_tests})")
        logger.error("ç³»ç»Ÿå­˜åœ¨ä¸¥é‡é—®é¢˜ï¼Œè¯·æ£€æŸ¥é…ç½®å’Œä¾èµ–")
    
    logger.info("=" * 60)
    
    return success_rate >= 0.6


if __name__ == "__main__":
    success = main()
    if not success:
        sys.exit(1)
