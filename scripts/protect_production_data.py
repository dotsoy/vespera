#!/usr/bin/env python3
"""
ç”Ÿäº§æ•°æ®ä¿æŠ¤è„šæœ¬
é˜²æ­¢æ„å¤–è¦†ç›–çœŸå®Aè‚¡ç”Ÿäº§æ•°æ®
"""
import sys
import os
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.utils.logger import get_logger

logger = get_logger("protect_production_data")


def check_production_data_exists():
    """æ£€æŸ¥ç”Ÿäº§æ•°æ®æ˜¯å¦å­˜åœ¨"""
    logger.info("ğŸ” æ£€æŸ¥ç”Ÿäº§æ•°æ®çŠ¶æ€")
    
    production_data_paths = [
        'data/production/a_share/a_share_basic.csv',
        'data/production/a_share/a_share_daily_quotes.csv'
    ]
    
    existing_files = []
    for path in production_data_paths:
        full_path = project_root / path
        if full_path.exists():
            existing_files.append(path)
            logger.info(f"âœ… å‘ç°ç”Ÿäº§æ•°æ®: {path}")
    
    if existing_files:
        logger.success(f"âœ… å‘ç° {len(existing_files)} ä¸ªç”Ÿäº§æ•°æ®æ–‡ä»¶")
        return True
    else:
        logger.warning("âš ï¸ æœªå‘ç°ç”Ÿäº§æ•°æ®æ–‡ä»¶")
        return False


def create_data_protection():
    """åˆ›å»ºæ•°æ®ä¿æŠ¤æœºåˆ¶"""
    logger.info("ğŸ›¡ï¸ åˆ›å»ºæ•°æ®ä¿æŠ¤æœºåˆ¶")
    
    try:
        # åˆ›å»ºä¿æŠ¤æ ‡è®°æ–‡ä»¶
        protection_file = project_root / 'data' / 'production' / '.PRODUCTION_DATA_PROTECTED'
        protection_file.parent.mkdir(parents=True, exist_ok=True)
        
        with open(protection_file, 'w', encoding='utf-8') as f:
            f.write("# ç”Ÿäº§æ•°æ®ä¿æŠ¤æ ‡è®°\n")
            f.write("# æ­¤æ–‡ä»¶è¡¨ç¤ºå½“å‰ç›®å½•åŒ…å«çœŸå®ç”Ÿäº§æ•°æ®\n")
            f.write("# è¯·å‹¿è¿è¡Œå¯èƒ½è¦†ç›–æ•°æ®çš„è„šæœ¬\n")
            f.write(f"# åˆ›å»ºæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write("\n")
            f.write("PRODUCTION_DATA=true\n")
            f.write("DATA_TYPE=A_SHARE_REAL\n")
            f.write("WARNING=DO_NOT_OVERWRITE\n")
        
        logger.success(f"âœ… ä¿æŠ¤æ ‡è®°å·²åˆ›å»º: {protection_file}")
        
        # åˆ›å»ºå±é™©è„šæœ¬è­¦å‘Š
        dangerous_scripts = [
            'scripts/import_a_share_data.py',
            'scripts/clear_mock_data.py',
            'scripts/production_data_manager.py'
        ]
        
        for script_path in dangerous_scripts:
            script_file = project_root / script_path
            if script_file.exists():
                # åœ¨è„šæœ¬å¼€å¤´æ·»åŠ è­¦å‘Šæ³¨é‡Š
                with open(script_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                if 'PRODUCTION_DATA_WARNING' not in content:
                    warning_header = '''#!/usr/bin/env python3
"""
âš ï¸ PRODUCTION_DATA_WARNING âš ï¸
æ­¤è„šæœ¬å¯èƒ½ä¼šè¦†ç›–çœŸå®çš„Aè‚¡ç”Ÿäº§æ•°æ®ï¼
è¿è¡Œå‰è¯·ç¡®è®¤æ‚¨äº†è§£é£é™©å¹¶æœ‰æ•°æ®å¤‡ä»½ã€‚
å¦‚éœ€è¿è¡Œï¼Œè¯·åˆ é™¤æ­¤è­¦å‘Šæ³¨é‡Šã€‚
"""
import sys
print("âš ï¸ è­¦å‘Šï¼šæ­¤è„šæœ¬å¯èƒ½è¦†ç›–ç”Ÿäº§æ•°æ®ï¼")
print("å¦‚éœ€ç»§ç»­ï¼Œè¯·æ‰‹åŠ¨åˆ é™¤è„šæœ¬ä¸­çš„è­¦å‘Šä»£ç ")
sys.exit(1)

'''
                    new_content = warning_header + content
                    
                    with open(script_file, 'w', encoding='utf-8') as f:
                        f.write(new_content)
                    
                    logger.warning(f"âš ï¸ å·²ä¸ºå±é™©è„šæœ¬æ·»åŠ ä¿æŠ¤: {script_path}")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ åˆ›å»ºæ•°æ®ä¿æŠ¤å¤±è´¥: {e}")
        return False


def backup_production_data():
    """å¤‡ä»½ç”Ÿäº§æ•°æ®"""
    logger.info("ğŸ’¾ å¤‡ä»½ç”Ÿäº§æ•°æ®")
    
    try:
        from datetime import datetime
        import shutil
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        backup_dir = project_root / 'backup' / 'production_data' / timestamp
        backup_dir.mkdir(parents=True, exist_ok=True)
        
        production_dir = project_root / 'data' / 'production'
        
        if production_dir.exists():
            # å¤åˆ¶æ•´ä¸ªç”Ÿäº§æ•°æ®ç›®å½•
            backup_production_dir = backup_dir / 'production'
            shutil.copytree(production_dir, backup_production_dir)
            
            logger.success(f"âœ… ç”Ÿäº§æ•°æ®å·²å¤‡ä»½åˆ°: {backup_dir}")
            
            # åˆ›å»ºå¤‡ä»½è¯´æ˜
            readme_file = backup_dir / 'README.md'
            with open(readme_file, 'w', encoding='utf-8') as f:
                f.write(f"# ç”Ÿäº§æ•°æ®å¤‡ä»½\n\n")
                f.write(f"å¤‡ä»½æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"å¤‡ä»½å†…å®¹: Aè‚¡çœŸå®ç”Ÿäº§æ•°æ®\n")
                f.write(f"æ•°æ®æ¥æº: AllTick + Alpha Vantage\n")
                f.write(f"å¤‡ä»½åŸå› : æ•°æ®ä¿æŠ¤\n\n")
                f.write(f"## æ¢å¤æ–¹æ³•\n")
                f.write(f"```bash\n")
                f.write(f"cp -r {backup_production_dir}/* data/production/\n")
                f.write(f"```\n")
            
            return True
        else:
            logger.warning("âš ï¸ ç”Ÿäº§æ•°æ®ç›®å½•ä¸å­˜åœ¨ï¼Œæ— éœ€å¤‡ä»½")
            return False
            
    except Exception as e:
        logger.error(f"âŒ å¤‡ä»½ç”Ÿäº§æ•°æ®å¤±è´¥: {e}")
        return False


def clean_sample_data():
    """æ¸…é™¤æ ·æœ¬æ•°æ®ï¼Œä¿ç•™çœŸå®æ•°æ®"""
    logger.info("ğŸ§¹ æ¸…é™¤æ ·æœ¬æ•°æ®")
    
    try:
        # éœ€è¦æ¸…é™¤çš„æ ·æœ¬æ•°æ®è·¯å¾„
        sample_paths = [
            'data/sample',
            'data/mock',
            'data/test',
            'data/temp'
        ]
        
        import shutil
        
        for path in sample_paths:
            full_path = project_root / path
            if full_path.exists():
                shutil.rmtree(full_path)
                logger.info(f"âœ… å·²æ¸…é™¤æ ·æœ¬æ•°æ®: {path}")
        
        logger.success("âœ… æ ·æœ¬æ•°æ®æ¸…é™¤å®Œæˆ")
        return True
        
    except Exception as e:
        logger.error(f"âŒ æ¸…é™¤æ ·æœ¬æ•°æ®å¤±è´¥: {e}")
        return False


def validate_data_integrity():
    """éªŒè¯æ•°æ®å®Œæ•´æ€§"""
    logger.info("ğŸ” éªŒè¯æ•°æ®å®Œæ•´æ€§")
    
    try:
        import pandas as pd
        
        # æ£€æŸ¥å…³é”®æ•°æ®æ–‡ä»¶
        key_files = {
            'data/production/a_share/a_share_basic.csv': 'è‚¡ç¥¨åŸºç¡€ä¿¡æ¯',
            'data/production/a_share/a_share_daily_quotes.csv': 'æ—¥çº¿è¡Œæƒ…æ•°æ®'
        }
        
        all_valid = True
        
        for file_path, description in key_files.items():
            full_path = project_root / file_path
            
            if full_path.exists():
                try:
                    data = pd.read_csv(full_path)
                    logger.success(f"âœ… {description}: {len(data)} æ¡è®°å½•")
                except Exception as e:
                    logger.error(f"âŒ {description} æ–‡ä»¶æŸå: {e}")
                    all_valid = False
            else:
                logger.error(f"âŒ {description} æ–‡ä»¶ç¼ºå¤±: {file_path}")
                all_valid = False
        
        if all_valid:
            logger.success("âœ… æ‰€æœ‰å…³é”®æ•°æ®æ–‡ä»¶å®Œæ•´")
        else:
            logger.error("âŒ å‘ç°æ•°æ®å®Œæ•´æ€§é—®é¢˜")
        
        return all_valid
        
    except Exception as e:
        logger.error(f"âŒ æ•°æ®å®Œæ•´æ€§éªŒè¯å¤±è´¥: {e}")
        return False


def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸ›¡ï¸ ç”Ÿäº§æ•°æ®ä¿æŠ¤ç³»ç»Ÿ")
    logger.info("=" * 60)
    
    try:
        from datetime import datetime
        
        # æ‰§è¡Œä¿æŠ¤æ­¥éª¤
        steps = [
            ("æ£€æŸ¥ç”Ÿäº§æ•°æ®", check_production_data_exists),
            ("å¤‡ä»½ç”Ÿäº§æ•°æ®", backup_production_data),
            ("åˆ›å»ºæ•°æ®ä¿æŠ¤", create_data_protection),
            ("æ¸…é™¤æ ·æœ¬æ•°æ®", clean_sample_data),
            ("éªŒè¯æ•°æ®å®Œæ•´æ€§", validate_data_integrity)
        ]
        
        success_count = 0
        total_count = len(steps)
        
        for step_name, step_func in steps:
            try:
                logger.info(f"\nğŸ¯ æ‰§è¡Œ: {step_name}")
                success = step_func()
                if success:
                    success_count += 1
                    logger.success(f"âœ… {step_name} å®Œæˆ")
                else:
                    logger.warning(f"âš ï¸ {step_name} éƒ¨åˆ†å®Œæˆ")
            except Exception as e:
                logger.error(f"âŒ {step_name} å¤±è´¥: {e}")
        
        # æ€»ç»“
        logger.info("\n" + "=" * 60)
        logger.info("ğŸ“Š ä¿æŠ¤æ“ä½œæ€»ç»“")
        logger.info("=" * 60)
        logger.info(f"æ€»æ­¥éª¤æ•°: {total_count}")
        logger.info(f"æˆåŠŸæ­¥éª¤: {success_count}")
        logger.info(f"æˆåŠŸç‡: {success_count/total_count*100:.1f}%")
        
        if success_count >= 4:  # è‡³å°‘4ä¸ªæ­¥éª¤æˆåŠŸ
            logger.success("ğŸ‰ ç”Ÿäº§æ•°æ®ä¿æŠ¤å®Œæˆï¼")
            logger.info("\nğŸ’¡ ä¿æŠ¤æªæ–½:")
            logger.info("  âœ… æ•°æ®å·²å¤‡ä»½")
            logger.info("  âœ… å±é™©è„šæœ¬å·²æ·»åŠ è­¦å‘Š")
            logger.info("  âœ… ä¿æŠ¤æ ‡è®°å·²åˆ›å»º")
            logger.info("  âœ… æ ·æœ¬æ•°æ®å·²æ¸…é™¤")
            
            logger.info("\nâš ï¸ é‡è¦æé†’:")
            logger.info("  â€¢ è¯·å‹¿è¿è¡Œå¸¦æœ‰è¦†ç›–è­¦å‘Šçš„è„šæœ¬")
            logger.info("  â€¢ å®šæœŸæ£€æŸ¥æ•°æ®å®Œæ•´æ€§")
            logger.info("  â€¢ å¦‚éœ€æ¢å¤æ•°æ®ï¼Œè¯·ä½¿ç”¨å¤‡ä»½")
        else:
            logger.warning("âš ï¸ éƒ¨åˆ†ä¿æŠ¤æªæ–½å¤±è´¥ï¼Œè¯·æ‰‹åŠ¨æ£€æŸ¥")
        
        return success_count >= 4
        
    except Exception as e:
        logger.error(f"âŒ ä¿æŠ¤ç³»ç»Ÿå¼‚å¸¸: {e}")
        return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
