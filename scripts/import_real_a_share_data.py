#!/usr/bin/env python3
"""
çœŸå®Aè‚¡æ•°æ®å¯¼å…¥è„šæœ¬
ä½¿ç”¨AkShare APIå¯¼å…¥çœŸå®çš„Aè‚¡æ•°æ®
1. å¯¼å…¥å…¨å¸‚åœºè‚¡ç¥¨åŸºç¡€ä¿¡æ¯
2. å¯¼å…¥æœ€æ–°äº¤æ˜“æ—¥å…¨å¸‚åœºæ—¥çº¿æ•°æ®
"""
import sys
import pandas as pd
from pathlib import Path
from datetime import datetime, timedelta

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.utils.logger import get_logger
from src.utils.database import get_db_manager
from src.data_sources.akshare_data_source import AkShareDataSource
from src.data_sources.base_data_source import DataRequest, DataType

logger = get_logger("real_a_share_import")


def import_stock_basic():
    """å¯¼å…¥è‚¡ç¥¨åŸºç¡€ä¿¡æ¯"""
    logger.info("ğŸ”„ å¼€å§‹å¯¼å…¥Aè‚¡åŸºç¡€ä¿¡æ¯...")

    try:
        # åˆå§‹åŒ–å®¢æˆ·ç«¯
        client = AkShareDataSource()
        db_manager = get_db_manager()

        # åˆå§‹åŒ–æ•°æ®æº
        if not client.initialize():
            logger.error("âŒ AkShareæ•°æ®æºåˆå§‹åŒ–å¤±è´¥")
            return False

        # è·å–è‚¡ç¥¨åŸºç¡€ä¿¡æ¯
        logger.info("ğŸ“¡ ä»AkShareè·å–è‚¡ç¥¨åŸºç¡€ä¿¡æ¯...")
        request = DataRequest(data_type=DataType.STOCK_BASIC)
        response = client.fetch_data(request)

        if not response.success or response.data.empty:
            logger.error("âŒ æœªè·å–åˆ°è‚¡ç¥¨åŸºç¡€ä¿¡æ¯")
            return False

        stock_basic_df = response.data
        logger.info(f"âœ… è·å–åˆ° {len(stock_basic_df)} åªè‚¡ç¥¨åŸºç¡€ä¿¡æ¯")

        # æ˜¾ç¤ºæ ·æœ¬æ•°æ®
        logger.info("ğŸ“‹ æ ·æœ¬æ•°æ®:")
        for _, row in stock_basic_df.head(5).iterrows():
            logger.info(f"  {row['ts_code']} - {row['name']} - {row['market']} - {row.get('industry', 'N/A')}")

        # ä¿å­˜åˆ°æ•°æ®åº“
        logger.info("ğŸ’¾ ä¿å­˜åˆ°æ•°æ®åº“...")

        # å…ˆåˆ é™¤ç°æœ‰æ•°æ®ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        try:
            db_manager.execute_postgres_command("DROP TABLE IF EXISTS stock_basic")
            logger.info("å·²åˆ é™¤ç°æœ‰stock_basicè¡¨")
        except Exception as e:
            logger.info(f"åˆ é™¤è¡¨å¤±è´¥ï¼ˆå¯èƒ½ä¸å­˜åœ¨ï¼‰: {e}")

        # æ’å…¥æ–°æ•°æ®
        db_manager.insert_dataframe_to_postgres(
            stock_basic_df, 'stock_basic', if_exists='append'
        )

        logger.info("âœ… è‚¡ç¥¨åŸºç¡€ä¿¡æ¯å¯¼å…¥å®Œæˆ!")
        return True

    except Exception as e:
        logger.error(f"âŒ å¯¼å…¥è‚¡ç¥¨åŸºç¡€ä¿¡æ¯å¤±è´¥: {e}")
        return False


def import_daily_quotes(trade_date=None):
    """å¯¼å…¥æŒ‡å®šæ—¥æœŸçš„æ—¥çº¿è¡Œæƒ…æ•°æ®"""
    if trade_date is None:
        # è·å–æœ€è¿‘çš„äº¤æ˜“æ—¥
        trade_date = (datetime.now() - timedelta(days=1)).strftime('%Y%m%d')

    logger.info(f"ğŸ”„ å¼€å§‹å¯¼å…¥ {trade_date} æ—¥çº¿è¡Œæƒ…æ•°æ®...")

    try:
        # åˆå§‹åŒ–å®¢æˆ·ç«¯
        client = AkShareDataSource()
        db_manager = get_db_manager()

        # åˆå§‹åŒ–æ•°æ®æº
        if not client.initialize():
            logger.error("âŒ AkShareæ•°æ®æºåˆå§‹åŒ–å¤±è´¥")
            return False

        # è·å–è‚¡ç¥¨åˆ—è¡¨
        logger.info("ğŸ“‹ è·å–è‚¡ç¥¨åˆ—è¡¨...")
        stock_query = """
        SELECT ts_code FROM stock_basic
        WHERE market IN ('æ·±äº¤æ‰€ä¸»æ¿', 'åˆ›ä¸šæ¿', 'ä¸Šäº¤æ‰€ä¸»æ¿', 'ç§‘åˆ›æ¿')
        ORDER BY ts_code
        LIMIT 50
        """
        stock_df = db_manager.execute_postgres_query(stock_query)

        if stock_df.empty:
            logger.error("âŒ æ•°æ®åº“ä¸­æ— è‚¡ç¥¨åŸºç¡€ä¿¡æ¯ï¼Œè¯·å…ˆå¯¼å…¥è‚¡ç¥¨åŸºç¡€ä¿¡æ¯")
            return False

        stock_list = stock_df['ts_code'].tolist()
        logger.info(f"ğŸ“Š å‡†å¤‡å¯¼å…¥ {len(stock_list)} åªè‚¡ç¥¨çš„ {trade_date} è¡Œæƒ…æ•°æ®")

        # é€ä¸ªè·å–è¡Œæƒ…æ•°æ®
        logger.info("ğŸ“¡ ä»AkShareè·å–è¡Œæƒ…æ•°æ®...")
        all_quotes = []
        success_count = 0

        # è½¬æ¢æ—¥æœŸæ ¼å¼
        target_date = datetime.strptime(trade_date, '%Y%m%d')

        for i, ts_code in enumerate(stock_list):
            try:
                request = DataRequest(
                    data_type=DataType.DAILY_QUOTES,
                    symbol=ts_code,
                    start_date=target_date,
                    end_date=target_date
                )
                response = client.fetch_data(request)

                if response.success and not response.data.empty:
                    all_quotes.append(response.data)
                    success_count += 1

                if (i + 1) % 10 == 0:
                    logger.info(f"å·²å¤„ç† {i+1}/{len(stock_list)} åªè‚¡ç¥¨ï¼ŒæˆåŠŸ {success_count} åª")

                # æ§åˆ¶é¢‘ç‡
                import time
                time.sleep(0.2)

            except Exception as e:
                logger.warning(f"è·å– {ts_code} æ•°æ®å¤±è´¥: {e}")
                continue

        if not all_quotes:
            logger.warning(f"âš ï¸ {trade_date} æœªè·å–åˆ°è¡Œæƒ…æ•°æ®ï¼ˆå¯èƒ½æ˜¯éäº¤æ˜“æ—¥ï¼‰")
            return False

        # åˆå¹¶æ•°æ®
        quotes_df = pd.concat(all_quotes, ignore_index=True)
        logger.info(f"âœ… è·å–åˆ° {len(quotes_df)} æ¡è¡Œæƒ…è®°å½•")

        # æ˜¾ç¤ºæ ·æœ¬æ•°æ®
        logger.info("ğŸ“‹ æ ·æœ¬æ•°æ®:")
        for _, row in quotes_df.head(5).iterrows():
            logger.info(f"  {row['ts_code']} - å¼€ç›˜:{row.get('open_price', 0):.2f} æ”¶ç›˜:{row.get('close_price', 0):.2f}")

        # ä¿å­˜åˆ°æ•°æ®åº“
        logger.info("ğŸ’¾ ä¿å­˜åˆ°æ•°æ®åº“...")
        db_manager.insert_dataframe_to_postgres(
            quotes_df, 'stock_daily_quotes', if_exists='append'
        )

        logger.info(f"âœ… {trade_date} æ—¥çº¿è¡Œæƒ…æ•°æ®å¯¼å…¥å®Œæˆ!")
        return True

    except Exception as e:
        logger.error(f"âŒ å¯¼å…¥æ—¥çº¿è¡Œæƒ…æ•°æ®å¤±è´¥: {e}")
        return False


def verify_import():
    """éªŒè¯å¯¼å…¥ç»“æœ"""
    logger.info("ğŸ” éªŒè¯å¯¼å…¥ç»“æœ...")
    
    try:
        db_manager = get_db_manager()
        
        # æ£€æŸ¥è‚¡ç¥¨åŸºç¡€ä¿¡æ¯
        stock_count_query = "SELECT COUNT(*) as count FROM stock_basic"
        stock_count_result = db_manager.execute_postgres_query(stock_count_query)
        stock_count = stock_count_result['count'].iloc[0] if not stock_count_result.empty else 0
        
        # æ£€æŸ¥æ—¥çº¿è¡Œæƒ…æ•°æ®
        quotes_count_query = "SELECT COUNT(*) as count FROM stock_daily_quotes"
        quotes_count_result = db_manager.execute_postgres_query(quotes_count_query)
        quotes_count = quotes_count_result['count'].iloc[0] if not quotes_count_result.empty else 0
        
        # æ£€æŸ¥æœ€æ–°æ•°æ®æ—¥æœŸ
        latest_date_query = "SELECT MAX(trade_date) as latest_date FROM stock_daily_quotes"
        latest_date_result = db_manager.execute_postgres_query(latest_date_query)
        latest_date = latest_date_result['latest_date'].iloc[0] if not latest_date_result.empty else None
        
        # æ˜¾ç¤ºç»“æœ
        logger.info("ğŸ“Š å¯¼å…¥ç»“æœç»Ÿè®¡:")
        logger.info(f"  è‚¡ç¥¨åŸºç¡€ä¿¡æ¯: {stock_count:,} æ¡")
        logger.info(f"  æ—¥çº¿è¡Œæƒ…æ•°æ®: {quotes_count:,} æ¡")
        logger.info(f"  æœ€æ–°æ•°æ®æ—¥æœŸ: {latest_date}")
        
        # æ˜¾ç¤ºå¸‚åœºåˆ†å¸ƒ
        if stock_count > 0:
            market_query = """
            SELECT market, COUNT(*) as count 
            FROM stock_basic 
            GROUP BY market 
            ORDER BY count DESC
            """
            market_result = db_manager.execute_postgres_query(market_query)
            
            logger.info("ğŸ“ˆ å¸‚åœºåˆ†å¸ƒ:")
            for _, row in market_result.iterrows():
                logger.info(f"  {row['market']}: {row['count']:,} åª")
        
        # æ˜¾ç¤ºè¡Œä¸šåˆ†å¸ƒï¼ˆå‰10ï¼‰
        if stock_count > 0:
            industry_query = """
            SELECT industry, COUNT(*) as count 
            FROM stock_basic 
            GROUP BY industry 
            ORDER BY count DESC 
            LIMIT 10
            """
            industry_result = db_manager.execute_postgres_query(industry_query)
            
            logger.info("ğŸ­ ä¸»è¦è¡Œä¸šåˆ†å¸ƒ:")
            for _, row in industry_result.iterrows():
                logger.info(f"  {row['industry']}: {row['count']:,} åª")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ éªŒè¯å¯¼å…¥ç»“æœå¤±è´¥: {e}")
        return False


def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸš€ å¼€å§‹çœŸå®Aè‚¡æ•°æ®å¯¼å…¥")
    logger.info("=" * 60)
    
    success_count = 0
    total_tasks = 3
    
    # 1. å¯¼å…¥è‚¡ç¥¨åŸºç¡€ä¿¡æ¯
    logger.info("\nğŸ“‹ ä»»åŠ¡ 1/3: å¯¼å…¥è‚¡ç¥¨åŸºç¡€ä¿¡æ¯")
    logger.info("-" * 40)
    if import_stock_basic():
        success_count += 1
        logger.info("âœ… ä»»åŠ¡ 1 å®Œæˆ")
    else:
        logger.error("âŒ ä»»åŠ¡ 1 å¤±è´¥")
    
    # 2. å¯¼å…¥æœ€æ–°äº¤æ˜“æ—¥æ—¥çº¿æ•°æ®
    logger.info("\nğŸ“ˆ ä»»åŠ¡ 2/3: å¯¼å…¥æœ€æ–°äº¤æ˜“æ—¥æ—¥çº¿æ•°æ®")
    logger.info("-" * 40)
    if import_daily_quotes():
        success_count += 1
        logger.info("âœ… ä»»åŠ¡ 2 å®Œæˆ")
    else:
        logger.error("âŒ ä»»åŠ¡ 2 å¤±è´¥")
    
    # 3. éªŒè¯å¯¼å…¥ç»“æœ
    logger.info("\nğŸ” ä»»åŠ¡ 3/3: éªŒè¯å¯¼å…¥ç»“æœ")
    logger.info("-" * 40)
    if verify_import():
        success_count += 1
        logger.info("âœ… ä»»åŠ¡ 3 å®Œæˆ")
    else:
        logger.error("âŒ ä»»åŠ¡ 3 å¤±è´¥")
    
    # æ€»ç»“
    logger.info("\n" + "=" * 60)
    logger.info("ğŸ“Š å¯¼å…¥ä»»åŠ¡æ€»ç»“")
    logger.info("=" * 60)
    logger.info(f"å®Œæˆä»»åŠ¡: {success_count}/{total_tasks}")
    
    if success_count == total_tasks:
        logger.info("ğŸ‰ æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼çœŸå®Aè‚¡æ•°æ®å¯¼å…¥æˆåŠŸ")
        logger.info("\nğŸš€ ä¸‹ä¸€æ­¥æ“ä½œ:")
        logger.info("1. è®¿é—®Dashboard: http://localhost:8505")
        logger.info("2. è¿›å…¥'æ•°æ®ç®¡ç†'é¡µé¢æŸ¥çœ‹å¯¼å…¥ç»“æœ")
        logger.info("3. åœ¨'ç­–ç•¥åˆ†æ'é¡µé¢é€‰æ‹©è‚¡ç¥¨è¿›è¡Œåˆ†æ")
        return True
    else:
        logger.error(f"âš ï¸ {total_tasks - success_count} ä¸ªä»»åŠ¡å¤±è´¥")
        logger.info("\nğŸ”§ æ•…éšœæ’é™¤:")
        logger.info("1. æ£€æŸ¥ç½‘ç»œè¿æ¥æ˜¯å¦ç¨³å®š")
        logger.info("2. æ£€æŸ¥æ•°æ®åº“è¿æ¥æ˜¯å¦æ­£å¸¸")
        logger.info("3. æ£€æŸ¥AkShareæ˜¯å¦å¯ä»¥æ­£å¸¸è®¿é—®")
        return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
