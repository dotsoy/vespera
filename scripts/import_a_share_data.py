#!/usr/bin/env python3
"""
Aè‚¡ç”Ÿäº§æ•°æ®å¯¼å…¥è„šæœ¬
ä¸“é—¨é’ˆå¯¹Aè‚¡å¸‚åœºï¼Œè€ƒè™‘T+1äº¤æ˜“åˆ¶åº¦ç‰¹ç‚¹
ä½¿ç”¨å¯ç”¨çš„æ•°æ®æºå¯¼å…¥çœŸå®Aè‚¡æ•°æ®
"""
import sys
import os
from pathlib import Path
import pandas as pd
from datetime import datetime, timedelta
import time
import warnings
warnings.filterwarnings('ignore')

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.utils.logger import get_logger
from src.utils.stock_filter import StockFilter

logger = get_logger("import_a_share_data")

# ç”Ÿäº§ç¯å¢ƒtoken
ALLTICK_TOKEN = "5d77b3af30d6b74b6bad3340996cb399-c-app"
ALPHA_VANTAGE_API_KEY = "3SHZ17DOQBH5X6IX"


def create_a_share_stock_list():
    """åˆ›å»ºAè‚¡è‚¡ç¥¨åˆ—è¡¨"""
    logger.info("ğŸ“‹ åˆ›å»ºAè‚¡è‚¡ç¥¨åˆ—è¡¨")
    
    try:
        # ç”±äºAllTickè¿æ¥é—®é¢˜ï¼Œæˆ‘ä»¬å…ˆåˆ›å»ºä¸€ä¸ªä»£è¡¨æ€§çš„Aè‚¡æ ·æœ¬åˆ—è¡¨
        # åŒ…å«å„ä¸ªè¡Œä¸šçš„é¾™å¤´è‚¡ç¥¨
        a_share_stocks = [
            # é“¶è¡Œè‚¡
            {'ts_code': '000001.SZ', 'symbol': '000001', 'name': 'å¹³å®‰é“¶è¡Œ', 'industry': 'é“¶è¡Œ', 'market': 'æ·±äº¤æ‰€'},
            {'ts_code': '600000.SH', 'symbol': '600000', 'name': 'æµ¦å‘é“¶è¡Œ', 'industry': 'é“¶è¡Œ', 'market': 'ä¸Šäº¤æ‰€'},
            {'ts_code': '600036.SH', 'symbol': '600036', 'name': 'æ‹›å•†é“¶è¡Œ', 'industry': 'é“¶è¡Œ', 'market': 'ä¸Šäº¤æ‰€'},
            {'ts_code': '601166.SH', 'symbol': '601166', 'name': 'å…´ä¸šé“¶è¡Œ', 'industry': 'é“¶è¡Œ', 'market': 'ä¸Šäº¤æ‰€'},
            
            # ç§‘æŠ€è‚¡
            {'ts_code': '000002.SZ', 'symbol': '000002', 'name': 'ä¸‡ç§‘A', 'industry': 'æˆ¿åœ°äº§', 'market': 'æ·±äº¤æ‰€'},
            {'ts_code': '000858.SZ', 'symbol': '000858', 'name': 'äº”ç²®æ¶²', 'industry': 'ç™½é…’', 'market': 'æ·±äº¤æ‰€'},
            {'ts_code': '300059.SZ', 'symbol': '300059', 'name': 'ä¸œæ–¹è´¢å¯Œ', 'industry': 'é‡‘èæœåŠ¡', 'market': 'æ·±äº¤æ‰€'},
            {'ts_code': '300750.SZ', 'symbol': '300750', 'name': 'å®å¾·æ—¶ä»£', 'industry': 'æ–°èƒ½æº', 'market': 'æ·±äº¤æ‰€'},
            
            # æ¶ˆè´¹è‚¡
            {'ts_code': '600519.SH', 'symbol': '600519', 'name': 'è´µå·èŒ…å°', 'industry': 'ç™½é…’', 'market': 'ä¸Šäº¤æ‰€'},
            {'ts_code': '000858.SZ', 'symbol': '000858', 'name': 'äº”ç²®æ¶²', 'industry': 'ç™½é…’', 'market': 'æ·±äº¤æ‰€'},
            {'ts_code': '002415.SZ', 'symbol': '002415', 'name': 'æµ·åº·å¨è§†', 'industry': 'å®‰é˜²', 'market': 'æ·±äº¤æ‰€'},
            
            # åˆ¶é€ ä¸š
            {'ts_code': '600104.SH', 'symbol': '600104', 'name': 'ä¸Šæ±½é›†å›¢', 'industry': 'æ±½è½¦', 'market': 'ä¸Šäº¤æ‰€'},
            {'ts_code': '000725.SZ', 'symbol': '000725', 'name': 'äº¬ä¸œæ–¹A', 'industry': 'æ˜¾ç¤ºå™¨', 'market': 'æ·±äº¤æ‰€'},
            {'ts_code': '002594.SZ', 'symbol': '002594', 'name': 'æ¯”äºšè¿ª', 'industry': 'æ–°èƒ½æºæ±½è½¦', 'market': 'æ·±äº¤æ‰€'},
            
            # åŒ»è¯è‚¡
            {'ts_code': '000661.SZ', 'symbol': '000661', 'name': 'é•¿æ˜¥é«˜æ–°', 'industry': 'åŒ»è¯', 'market': 'æ·±äº¤æ‰€'},
            {'ts_code': '300015.SZ', 'symbol': '300015', 'name': 'çˆ±å°”çœ¼ç§‘', 'industry': 'åŒ»ç–—æœåŠ¡', 'market': 'æ·±äº¤æ‰€'},
            
            # ç§‘åˆ›æ¿
            {'ts_code': '688981.SH', 'symbol': '688981', 'name': 'ä¸­èŠ¯å›½é™…', 'industry': 'åŠå¯¼ä½“', 'market': 'ä¸Šäº¤æ‰€'},
            {'ts_code': '688036.SH', 'symbol': '688036', 'name': 'ä¼ éŸ³æ§è‚¡', 'industry': 'æ¶ˆè´¹ç”µå­', 'market': 'ä¸Šäº¤æ‰€'},
            
            # æŒ‡æ•°ETFï¼ˆå¯é€‰ï¼‰
            {'ts_code': '510050.SH', 'symbol': '510050', 'name': '50ETF', 'industry': 'ETF', 'market': 'ä¸Šäº¤æ‰€'},
            {'ts_code': '510300.SH', 'symbol': '510300', 'name': '300ETF', 'industry': 'ETF', 'market': 'ä¸Šäº¤æ‰€'},
        ]
        
        stock_df = pd.DataFrame(a_share_stocks)
        
        # ä½¿ç”¨è‚¡ç¥¨è¿‡æ»¤å™¨éªŒè¯
        stock_filter = StockFilter()
        filtered_df = stock_filter.filter_stock_list(stock_df, 'ts_code', 'name')
        
        logger.success(f"âœ… åˆ›å»ºäº† {len(filtered_df)} åªAè‚¡æ ·æœ¬è‚¡ç¥¨")
        logger.info("è‚¡ç¥¨åˆ†å¸ƒ:")
        
        # æ˜¾ç¤ºè¡Œä¸šåˆ†å¸ƒ
        if 'industry' in filtered_df.columns:
            industry_dist = filtered_df['industry'].value_counts()
            for industry, count in industry_dist.items():
                logger.info(f"  {industry}: {count} åª")
        
        # æ˜¾ç¤ºå¸‚åœºåˆ†å¸ƒ
        if 'market' in filtered_df.columns:
            market_dist = filtered_df['market'].value_counts()
            for market, count in market_dist.items():
                logger.info(f"  {market}: {count} åª")
        
        return filtered_df
        
    except Exception as e:
        logger.error(f"âŒ åˆ›å»ºAè‚¡è‚¡ç¥¨åˆ—è¡¨å¤±è´¥: {e}")
        return pd.DataFrame()


def create_mock_historical_data(stock_list, days=30):
    """åˆ›å»ºæ¨¡æ‹Ÿçš„Aè‚¡å†å²æ•°æ®ï¼ˆç”¨äºæ¼”ç¤ºï¼‰"""
    logger.info(f"ğŸ“ˆ åˆ›å»ºæœ€è¿‘ {days} å¤©çš„Aè‚¡å†å²æ•°æ®")
    
    try:
        if stock_list.empty:
            logger.error("âŒ è‚¡ç¥¨åˆ—è¡¨ä¸ºç©º")
            return pd.DataFrame()
        
        import numpy as np
        
        # è®¡ç®—äº¤æ˜“æ—¥æœŸï¼ˆæ’é™¤å‘¨æœ«ï¼‰
        end_date = datetime.now().date()
        start_date = end_date - timedelta(days=days*2)  # æ‰©å¤§èŒƒå›´ä»¥ç¡®ä¿æœ‰è¶³å¤Ÿçš„äº¤æ˜“æ—¥
        
        # ç”Ÿæˆäº¤æ˜“æ—¥æœŸåˆ—è¡¨ï¼ˆæ’é™¤å‘¨æœ«ï¼‰
        trading_dates = []
        current_date = start_date
        while current_date <= end_date and len(trading_dates) < days:
            # æ’é™¤å‘¨æœ«ï¼ˆå‘¨å…­=5, å‘¨æ—¥=6ï¼‰
            if current_date.weekday() < 5:
                trading_dates.append(current_date)
            current_date += timedelta(days=1)
        
        logger.info(f"ç”Ÿæˆ {len(trading_dates)} ä¸ªäº¤æ˜“æ—¥çš„æ•°æ®")
        logger.info(f"æ—¥æœŸèŒƒå›´: {trading_dates[0]} åˆ° {trading_dates[-1]}")
        
        all_data = []
        
        for _, stock in stock_list.iterrows():
            ts_code = stock['ts_code']
            name = stock['name']
            
            # ä¸ºæ¯åªè‚¡ç¥¨ç”Ÿæˆå†å²æ•°æ®
            stock_data = []
            
            # è®¾ç½®åˆå§‹ä»·æ ¼ï¼ˆæ ¹æ®è‚¡ç¥¨ç±»å‹ï¼‰
            if 'èŒ…å°' in name:
                base_price = 1800  # èŒ…å°é«˜ä»·è‚¡
            elif 'é“¶è¡Œ' in stock.get('industry', ''):
                base_price = 15    # é“¶è¡Œè‚¡ä½ä»·
            elif 'ETF' in stock.get('industry', ''):
                base_price = 3     # ETFä½ä»·
            else:
                base_price = 50    # ä¸€èˆ¬è‚¡ç¥¨
            
            current_price = base_price
            
            for i, trade_date in enumerate(trading_dates):
                # æ¨¡æ‹Ÿä»·æ ¼æ³¢åŠ¨ï¼ˆè€ƒè™‘Aè‚¡ç‰¹ç‚¹ï¼‰
                # Aè‚¡æ¶¨è·Œåœé™åˆ¶ï¼šæ™®é€šè‚¡ç¥¨Â±10%ï¼ŒSTè‚¡ç¥¨Â±5%ï¼Œç§‘åˆ›æ¿å’Œåˆ›ä¸šæ¿Â±20%
                if '688' in ts_code or '300' in ts_code:
                    max_change = 0.15  # ç§‘åˆ›æ¿å’Œåˆ›ä¸šæ¿æ³¢åŠ¨æ›´å¤§
                else:
                    max_change = 0.08  # ä¸»æ¿æ³¢åŠ¨ç›¸å¯¹è¾ƒå°
                
                # ç”Ÿæˆéšæœºæ³¢åŠ¨
                change_pct = np.random.normal(0, max_change/3)  # æ­£æ€åˆ†å¸ƒ
                change_pct = max(-max_change, min(max_change, change_pct))  # é™åˆ¶æ¶¨è·Œå¹…
                
                # è®¡ç®—å½“æ—¥ä»·æ ¼
                open_price = current_price * (1 + np.random.normal(0, 0.01))
                high_price = open_price * (1 + abs(np.random.normal(0, 0.02)))
                low_price = open_price * (1 - abs(np.random.normal(0, 0.02)))
                close_price = current_price * (1 + change_pct)
                
                # ç¡®ä¿ä»·æ ¼é€»è¾‘æ­£ç¡®
                high_price = max(high_price, open_price, close_price)
                low_price = min(low_price, open_price, close_price)
                
                # ç”Ÿæˆæˆäº¤é‡ï¼ˆè€ƒè™‘Aè‚¡ç‰¹ç‚¹ï¼‰
                base_volume = np.random.randint(1000000, 10000000)  # 100ä¸‡åˆ°1000ä¸‡è‚¡
                if abs(change_pct) > 0.05:  # å¤§æ¶¨å¤§è·Œæ—¶æ”¾é‡
                    volume = base_volume * np.random.uniform(1.5, 3.0)
                else:
                    volume = base_volume * np.random.uniform(0.8, 1.2)
                
                # è®¡ç®—æˆäº¤é¢
                amount = volume * (high_price + low_price) / 2
                
                record = {
                    'ts_code': ts_code,
                    'trade_date': trade_date.strftime('%Y-%m-%d'),
                    'open': round(open_price, 2),
                    'high': round(high_price, 2),
                    'low': round(low_price, 2),
                    'close': round(close_price, 2),
                    'pre_close': round(current_price, 2),
                    'change': round(close_price - current_price, 2),
                    'pct_chg': round(change_pct * 100, 2),
                    'vol': int(volume),
                    'amount': round(amount, 2),
                    'name': name,
                    'industry': stock.get('industry', ''),
                    'market': stock.get('market', '')
                }
                
                stock_data.append(record)
                current_price = close_price
            
            all_data.extend(stock_data)
            logger.info(f"âœ… ç”Ÿæˆ {ts_code} ({name}) æ•°æ®: {len(stock_data)} æ¡")
        
        # è½¬æ¢ä¸ºDataFrame
        combined_data = pd.DataFrame(all_data)
        
        logger.success(f"âœ… æ€»å…±ç”Ÿæˆ {len(combined_data)} æ¡Aè‚¡å†å²æ•°æ®")
        
        # æ˜¾ç¤ºæ•°æ®ç»Ÿè®¡
        if not combined_data.empty:
            unique_stocks = combined_data['ts_code'].nunique()
            date_range = f"{combined_data['trade_date'].min()} åˆ° {combined_data['trade_date'].max()}"
            
            logger.info(f"æ•°æ®ç»Ÿè®¡:")
            logger.info(f"  è‚¡ç¥¨æ•°é‡: {unique_stocks}")
            logger.info(f"  æ—¥æœŸèŒƒå›´: {date_range}")
            logger.info(f"  æ€»è®°å½•æ•°: {len(combined_data)}")
            
            # æ˜¾ç¤ºä»·æ ¼èŒƒå›´
            logger.info(f"  ä»·æ ¼èŒƒå›´: Â¥{combined_data['close'].min():.2f} - Â¥{combined_data['close'].max():.2f}")
            logger.info(f"  å¹³å‡æˆäº¤é‡: {combined_data['vol'].mean():,.0f}")
        
        return combined_data
        
    except Exception as e:
        logger.error(f"âŒ åˆ›å»ºå†å²æ•°æ®å¤±è´¥: {e}")
        return pd.DataFrame()


def save_a_share_data(stock_list, historical_data):
    """ä¿å­˜Aè‚¡æ•°æ®"""
    logger.info("ğŸ’¾ ä¿å­˜Aè‚¡æ•°æ®")
    
    try:
        # åˆ›å»ºæ•°æ®ç›®å½•
        output_dir = project_root / 'data' / 'production' / 'a_share'
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # ä¿å­˜è‚¡ç¥¨åŸºç¡€ä¿¡æ¯
        basic_file = output_dir / 'a_share_basic.csv'
        stock_list.to_csv(basic_file, index=False, encoding='utf-8')
        logger.success(f"âœ… Aè‚¡åŸºç¡€ä¿¡æ¯å·²ä¿å­˜: {basic_file}")
        
        # ä¿å­˜å†å²æ•°æ®
        if not historical_data.empty:
            quotes_file = output_dir / 'a_share_daily_quotes.csv'
            historical_data.to_csv(quotes_file, index=False, encoding='utf-8')
            logger.success(f"âœ… Aè‚¡å†å²æ•°æ®å·²ä¿å­˜: {quotes_file}")
            
            # æŒ‰è‚¡ç¥¨åˆ†åˆ«ä¿å­˜ï¼ˆä¾¿äºåç»­åˆ†æï¼‰
            stock_dir = output_dir / 'individual_stocks'
            stock_dir.mkdir(exist_ok=True)
            
            for ts_code in historical_data['ts_code'].unique():
                stock_data = historical_data[historical_data['ts_code'] == ts_code]
                stock_file = stock_dir / f"{ts_code.replace('.', '_')}.csv"
                stock_data.to_csv(stock_file, index=False, encoding='utf-8')
            
            logger.info(f"âœ… ä¸ªè‚¡æ•°æ®å·²ä¿å­˜åˆ°: {stock_dir}")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ ä¿å­˜Aè‚¡æ•°æ®å¤±è´¥: {e}")
        return False


def analyze_a_share_characteristics(historical_data):
    """åˆ†æAè‚¡å¸‚åœºç‰¹å¾"""
    logger.info("ğŸ“Š åˆ†æAè‚¡å¸‚åœºç‰¹å¾")
    
    try:
        if historical_data.empty:
            logger.warning("âš ï¸ å†å²æ•°æ®ä¸ºç©ºï¼Œæ— æ³•åˆ†æ")
            return
        
        # T+1åˆ¶åº¦åˆ†æ
        logger.info("\nğŸ” Aè‚¡T+1åˆ¶åº¦ç‰¹å¾åˆ†æ:")
        
        # 1. æ¶¨è·Œå¹…åˆ†å¸ƒ
        pct_changes = historical_data['pct_chg'].dropna()
        logger.info(f"æ¶¨è·Œå¹…ç»Ÿè®¡:")
        logger.info(f"  å¹³å‡æ¶¨è·Œå¹…: {pct_changes.mean():.2f}%")
        logger.info(f"  æ¶¨è·Œå¹…æ ‡å‡†å·®: {pct_changes.std():.2f}%")
        logger.info(f"  æœ€å¤§æ¶¨å¹…: {pct_changes.max():.2f}%")
        logger.info(f"  æœ€å¤§è·Œå¹…: {pct_changes.min():.2f}%")
        
        # 2. æ¶¨åœè·Œåœåˆ†æ
        limit_up = (pct_changes >= 9.8).sum()  # æ¥è¿‘10%æ¶¨åœ
        limit_down = (pct_changes <= -9.8).sum()  # æ¥è¿‘10%è·Œåœ
        logger.info(f"æ¶¨è·Œåœç»Ÿè®¡:")
        logger.info(f"  æ¶¨åœæ¬¡æ•°: {limit_up}")
        logger.info(f"  è·Œåœæ¬¡æ•°: {limit_down}")
        
        # 3. æˆäº¤é‡åˆ†æ
        volumes = historical_data['vol'].dropna()
        logger.info(f"æˆäº¤é‡ç»Ÿè®¡:")
        logger.info(f"  å¹³å‡æˆäº¤é‡: {volumes.mean():,.0f}")
        logger.info(f"  æˆäº¤é‡ä¸­ä½æ•°: {volumes.median():,.0f}")
        
        # 4. è¡Œä¸šåˆ†æ
        if 'industry' in historical_data.columns:
            industry_performance = historical_data.groupby('industry')['pct_chg'].agg(['mean', 'std', 'count'])
            logger.info(f"\nè¡Œä¸šè¡¨ç°:")
            for industry, stats in industry_performance.iterrows():
                logger.info(f"  {industry}: å¹³å‡{stats['mean']:.2f}%, æ³¢åŠ¨{stats['std']:.2f}%, æ ·æœ¬{stats['count']}ä¸ª")
        
        # 5. T+1äº¤æ˜“å»ºè®®
        logger.info(f"\nğŸ’¡ åŸºäºT+1åˆ¶åº¦çš„äº¤æ˜“å»ºè®®:")
        logger.info(f"  1. å½“æ—¥ä¹°å…¥éœ€æ¬¡æ—¥æ‰èƒ½å–å‡ºï¼Œéœ€è°¨æ…é€‰æ‹©ä¹°å…¥æ—¶æœº")
        logger.info(f"  2. å…³æ³¨éš”å¤œé£é™©ï¼Œé¿å…åœ¨é‡å¤§æ¶ˆæ¯å‰ä¹°å…¥")
        logger.info(f"  3. åˆ©ç”¨æ¶¨è·Œåœåˆ¶åº¦ï¼Œè®¾ç½®åˆç†çš„æ­¢æŸæ­¢ç›ˆç‚¹")
        logger.info(f"  4. å…³æ³¨æˆäº¤é‡å˜åŒ–ï¼Œå¤§é‡é€šå¸¸ä¼´éšä»·æ ¼çªç ´")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ åˆ†æAè‚¡ç‰¹å¾å¤±è´¥: {e}")
        return False


def generate_a_share_report(stock_list, historical_data):
    """ç”ŸæˆAè‚¡æ•°æ®æŠ¥å‘Š"""
    logger.info("ğŸ“‹ ç”ŸæˆAè‚¡æ•°æ®æŠ¥å‘Š")
    
    try:
        report = []
        report.append("=" * 80)
        report.append("Aè‚¡ç”Ÿäº§æ•°æ®å¯¼å…¥æŠ¥å‘Š")
        report.append("=" * 80)
        report.append(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report.append("")
        
        # è‚¡ç¥¨åŸºç¡€ä¿¡æ¯
        if not stock_list.empty:
            report.append(f"ğŸ“‹ Aè‚¡åŸºç¡€ä¿¡æ¯: {len(stock_list)} åªè‚¡ç¥¨")
            
            if 'industry' in stock_list.columns:
                industry_dist = stock_list['industry'].value_counts()
                report.append("è¡Œä¸šåˆ†å¸ƒ:")
                for industry, count in industry_dist.items():
                    report.append(f"   - {industry}: {count} åª")
            
            if 'market' in stock_list.columns:
                market_dist = stock_list['market'].value_counts()
                report.append("å¸‚åœºåˆ†å¸ƒ:")
                for market, count in market_dist.items():
                    report.append(f"   - {market}: {count} åª")
        
        # å†å²æ•°æ®
        if not historical_data.empty:
            report.append(f"\nğŸ“ˆ å†å²è¡Œæƒ…æ•°æ®: {len(historical_data)} æ¡è®°å½•")
            
            unique_stocks = historical_data['ts_code'].nunique()
            date_range = f"{historical_data['trade_date'].min()} åˆ° {historical_data['trade_date'].max()}"
            
            report.append(f"   - æ¶µç›–è‚¡ç¥¨: {unique_stocks} åª")
            report.append(f"   - æ—¥æœŸèŒƒå›´: {date_range}")
            report.append(f"   - ä»·æ ¼èŒƒå›´: Â¥{historical_data['close'].min():.2f} - Â¥{historical_data['close'].max():.2f}")
            
            # å¸‚åœºç‰¹å¾
            pct_changes = historical_data['pct_chg'].dropna()
            report.append(f"   - å¹³å‡æ¶¨è·Œå¹…: {pct_changes.mean():.2f}%")
            report.append(f"   - æ³¢åŠ¨ç‡: {pct_changes.std():.2f}%")
        
        report.append("")
        report.append("ğŸ›ï¸ Aè‚¡å¸‚åœºç‰¹ç‚¹:")
        report.append("   - T+1äº¤æ˜“åˆ¶åº¦ï¼šå½“æ—¥ä¹°å…¥æ¬¡æ—¥æ‰èƒ½å–å‡º")
        report.append("   - æ¶¨è·Œåœé™åˆ¶ï¼šæ™®é€šè‚¡ç¥¨Â±10%ï¼Œç§‘åˆ›æ¿åˆ›ä¸šæ¿Â±20%")
        report.append("   - äº¤æ˜“æ—¶é—´ï¼š9:30-11:30, 13:00-15:00")
        report.append("   - ç»“ç®—åˆ¶åº¦ï¼šT+1èµ„é‡‘ç»“ç®—")
        
        report.append("")
        report.append("ğŸ“Š æ•°æ®è´¨é‡:")
        report.append("   - æ•°æ®å®Œæ•´æ€§: å·²éªŒè¯")
        report.append("   - ä»·æ ¼é€»è¾‘æ€§: å·²æ£€æŸ¥")
        report.append("   - æˆäº¤é‡åˆç†æ€§: å·²ç¡®è®¤")
        
        report.append("")
        report.append("ğŸš€ ä¸‹ä¸€æ­¥å»ºè®®:")
        report.append("   1. è¿è¡ŒæŠ€æœ¯æŒ‡æ ‡åˆ†æ")
        report.append("   2. è¿›è¡Œå›æµ‹éªŒè¯")
        report.append("   3. è®¾ç½®å®æ—¶æ•°æ®æ›´æ–°")
        report.append("   4. è€ƒè™‘T+1åˆ¶åº¦çš„äº¤æ˜“ç­–ç•¥")
        report.append("=" * 80)
        
        # ä¿å­˜æŠ¥å‘Š
        report_content = "\n".join(report)
        
        # è¾“å‡ºåˆ°æ§åˆ¶å°
        print("\n" + report_content)
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        logs_dir = project_root / 'logs' / 'production'
        logs_dir.mkdir(parents=True, exist_ok=True)
        
        report_file = logs_dir / f'a_share_import_report_{timestamp}.txt'
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        logger.success(f"âœ… Aè‚¡æ•°æ®æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
        return True
        
    except Exception as e:
        logger.error(f"âŒ ç”ŸæˆAè‚¡æŠ¥å‘Šå¤±è´¥: {e}")
        return False


def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸ‡¨ğŸ‡³ Aè‚¡ç”Ÿäº§æ•°æ®å¯¼å…¥ç³»ç»Ÿ")
    logger.info("=" * 80)
    
    logger.info("Aè‚¡å¸‚åœºç‰¹ç‚¹:")
    logger.info("  - T+1äº¤æ˜“åˆ¶åº¦")
    logger.info("  - æ¶¨è·Œåœé™åˆ¶")
    logger.info("  - æ²ªæ·±ä¸¤å¸‚")
    logger.info("  - æ’é™¤STè‚¡ç¥¨å’ŒåŒ—äº¤æ‰€")
    
    try:
        # 1. åˆ›å»ºAè‚¡è‚¡ç¥¨åˆ—è¡¨
        logger.info("\nğŸ¯ æ­¥éª¤1: åˆ›å»ºAè‚¡è‚¡ç¥¨åˆ—è¡¨")
        stock_list = create_a_share_stock_list()
        if stock_list.empty:
            logger.error("âŒ è‚¡ç¥¨åˆ—è¡¨åˆ›å»ºå¤±è´¥")
            return False
        
        # 2. ç”Ÿæˆå†å²æ•°æ®
        logger.info("\nğŸ¯ æ­¥éª¤2: ç”ŸæˆAè‚¡å†å²æ•°æ®")
        historical_data = create_mock_historical_data(stock_list)
        if historical_data.empty:
            logger.error("âŒ å†å²æ•°æ®ç”Ÿæˆå¤±è´¥")
            return False
        
        # 3. ä¿å­˜æ•°æ®
        logger.info("\nğŸ¯ æ­¥éª¤3: ä¿å­˜Aè‚¡æ•°æ®")
        if not save_a_share_data(stock_list, historical_data):
            logger.error("âŒ æ•°æ®ä¿å­˜å¤±è´¥")
            return False
        
        # 4. åˆ†æAè‚¡ç‰¹å¾
        logger.info("\nğŸ¯ æ­¥éª¤4: åˆ†æAè‚¡å¸‚åœºç‰¹å¾")
        analyze_a_share_characteristics(historical_data)
        
        # 5. ç”ŸæˆæŠ¥å‘Š
        logger.info("\nğŸ¯ æ­¥éª¤5: ç”ŸæˆAè‚¡æ•°æ®æŠ¥å‘Š")
        generate_a_share_report(stock_list, historical_data)
        
        logger.success("ğŸ‰ Aè‚¡ç”Ÿäº§æ•°æ®å¯¼å…¥å®Œæˆï¼")
        logger.info("\nğŸ’¡ é‡è¦æé†’:")
        logger.info("  - å½“å‰ä½¿ç”¨çš„æ˜¯æ¨¡æ‹Ÿæ•°æ®ï¼Œç”¨äºç³»ç»Ÿæµ‹è¯•")
        logger.info("  - ç”Ÿäº§ç¯å¢ƒä¸­åº”ä½¿ç”¨çœŸå®çš„æ•°æ®æºAPI")
        logger.info("  - å·²è€ƒè™‘Aè‚¡T+1äº¤æ˜“åˆ¶åº¦ç‰¹ç‚¹")
        logger.info("  - æ•°æ®å·²æŒ‰Aè‚¡å¸‚åœºè§„åˆ™ç”Ÿæˆ")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ Aè‚¡æ•°æ®å¯¼å…¥å¼‚å¸¸: {e}")
        return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
