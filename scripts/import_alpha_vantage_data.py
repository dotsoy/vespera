#!/usr/bin/env python3
"""
ä½¿ç”¨Alpha Vantageå¯¼å…¥ç”Ÿäº§æ•°æ®
ç”±äºAllTickè¿æ¥é—®é¢˜ï¼Œä½¿ç”¨Alpha Vantageä½œä¸ºä¸»è¦æ•°æ®æº
"""
import sys
import os
from pathlib import Path
import pandas as pd
from datetime import datetime, timedelta
import time
import warnings
warnings.filterwarnings('ignore')

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.utils.logger import get_logger
from src.utils.stock_filter import StockFilter
from src.data_sources.base_data_source import DataRequest, DataType
from src.data_sources.alpha_vantage_data_source import AlphaVantageDataSource

logger = get_logger("import_alpha_vantage_data")

# Alpha Vantage API Key
ALPHA_VANTAGE_API_KEY = "3SHZ17DOQBH5X6IX"


def create_sample_stock_list():
    """åˆ›å»ºæ ·æœ¬è‚¡ç¥¨åˆ—è¡¨ï¼ˆAè‚¡ä¸»è¦è‚¡ç¥¨ï¼‰"""
    logger.info("ğŸ“‹ åˆ›å»ºæ ·æœ¬è‚¡ç¥¨åˆ—è¡¨")
    
    # ç”±äºAlpha Vantageä¸»è¦æ”¯æŒç¾è‚¡ï¼Œæˆ‘ä»¬åˆ›å»ºä¸€äº›çŸ¥åçš„ä¸­æ¦‚è‚¡å’Œç¾è‚¡
    sample_stocks = [
        # ä¸­æ¦‚è‚¡
        {'symbol': 'BABA', 'name': 'é˜¿é‡Œå·´å·´', 'market': 'US'},
        {'symbol': 'JD', 'name': 'äº¬ä¸œ', 'market': 'US'},
        {'symbol': 'BIDU', 'name': 'ç™¾åº¦', 'market': 'US'},
        {'symbol': 'NTES', 'name': 'ç½‘æ˜“', 'market': 'US'},
        {'symbol': 'PDD', 'name': 'æ‹¼å¤šå¤š', 'market': 'US'},
        
        # ç¾è‚¡çŸ¥åè‚¡ç¥¨
        {'symbol': 'AAPL', 'name': 'è‹¹æœ', 'market': 'US'},
        {'symbol': 'MSFT', 'name': 'å¾®è½¯', 'market': 'US'},
        {'symbol': 'GOOGL', 'name': 'è°·æ­Œ', 'market': 'US'},
        {'symbol': 'AMZN', 'name': 'äºšé©¬é€Š', 'market': 'US'},
        {'symbol': 'TSLA', 'name': 'ç‰¹æ–¯æ‹‰', 'market': 'US'},
        {'symbol': 'NVDA', 'name': 'è‹±ä¼Ÿè¾¾', 'market': 'US'},
        {'symbol': 'META', 'name': 'Meta', 'market': 'US'},
        
        # é‡‘èè‚¡
        {'symbol': 'JPM', 'name': 'æ‘©æ ¹å¤§é€š', 'market': 'US'},
        {'symbol': 'BAC', 'name': 'ç¾å›½é“¶è¡Œ', 'market': 'US'},
        {'symbol': 'WFC', 'name': 'å¯Œå›½é“¶è¡Œ', 'market': 'US'},
    ]
    
    stock_df = pd.DataFrame(sample_stocks)
    
    logger.success(f"âœ… åˆ›å»ºäº† {len(stock_df)} åªæ ·æœ¬è‚¡ç¥¨")
    logger.info("è‚¡ç¥¨åˆ—è¡¨:")
    print(stock_df.to_string())
    
    return stock_df


def setup_alpha_vantage():
    """è®¾ç½®Alpha Vantageæ•°æ®æº"""
    logger.info("ğŸ”§ è®¾ç½®Alpha Vantageæ•°æ®æº")
    
    try:
        config = {
            'priority': 1,
            'rate_limit': 5,  # Alpha Vantageå…è´¹ç‰ˆé™åˆ¶
            'timeout': 30,
            'description': 'Alpha Vantageç”Ÿäº§ç¯å¢ƒ'
        }
        
        alpha_source = AlphaVantageDataSource(ALPHA_VANTAGE_API_KEY, config)
        
        if alpha_source.initialize():
            logger.success("âœ… Alpha Vantageæ•°æ®æºé…ç½®æˆåŠŸ")
            return alpha_source
        else:
            logger.error("âŒ Alpha Vantageæ•°æ®æºåˆå§‹åŒ–å¤±è´¥")
            return None
            
    except Exception as e:
        logger.error(f"âŒ Alpha Vantageé…ç½®å¤±è´¥: {e}")
        return None


def import_stock_data(alpha_source, stock_list, days=30):
    """å¯¼å…¥è‚¡ç¥¨æ•°æ®"""
    logger.info(f"ğŸ“ˆ å¯¼å…¥æœ€è¿‘ {days} å¤©çš„è‚¡ç¥¨æ•°æ®")
    
    try:
        if stock_list.empty:
            logger.error("âŒ è‚¡ç¥¨åˆ—è¡¨ä¸ºç©º")
            return False
        
        # è®¡ç®—æ—¥æœŸèŒƒå›´
        end_date = datetime.now().date()
        start_date = end_date - timedelta(days=days)
        
        logger.info(f"æ•°æ®æ—¥æœŸèŒƒå›´: {start_date} åˆ° {end_date}")
        
        all_data = []
        success_count = 0
        total_count = len(stock_list)
        
        for idx, (_, stock) in enumerate(stock_list.iterrows(), 1):
            symbol = stock['symbol']
            name = stock['name']
            
            logger.info(f"[{idx}/{total_count}] è·å– {symbol} ({name}) çš„æ•°æ®")
            
            try:
                request = DataRequest(
                    data_type=DataType.DAILY_QUOTES,
                    symbol=symbol,
                    start_date=start_date.strftime('%Y-%m-%d'),
                    end_date=end_date.strftime('%Y-%m-%d')
                )
                
                response = alpha_source.fetch_data(request)
                
                if response.success and not response.data.empty:
                    # æ·»åŠ è‚¡ç¥¨ä¿¡æ¯
                    data_with_info = response.data.copy()
                    data_with_info['symbol'] = symbol
                    data_with_info['name'] = name
                    data_with_info['market'] = stock['market']
                    
                    all_data.append(data_with_info)
                    success_count += 1
                    logger.success(f"âœ… è·å–æˆåŠŸï¼Œ{len(response.data)} æ¡è®°å½•")
                else:
                    logger.warning(f"âš ï¸ è·å–å¤±è´¥: {response.error_message}")
                
                # æ§åˆ¶è¯·æ±‚é¢‘ç‡ - Alpha Vantageå…è´¹ç‰ˆé™åˆ¶
                time.sleep(12)  # æ¯åˆ†é’Ÿ5æ¬¡è¯·æ±‚
                
            except Exception as e:
                logger.warning(f"âš ï¸ è·å– {symbol} æ•°æ®æ—¶å‡ºé”™: {e}")
                continue
        
        # åˆå¹¶æ‰€æœ‰æ•°æ®
        if all_data:
            combined_data = pd.concat(all_data, ignore_index=True)
            
            # ä¿å­˜æ•°æ®
            output_dir = project_root / 'data' / 'production'
            output_dir.mkdir(parents=True, exist_ok=True)
            
            # ä¿å­˜è‚¡ç¥¨åŸºç¡€ä¿¡æ¯
            basic_file = output_dir / 'stock_basic.csv'
            stock_list.to_csv(basic_file, index=False, encoding='utf-8')
            logger.success(f"âœ… è‚¡ç¥¨åŸºç¡€ä¿¡æ¯å·²ä¿å­˜åˆ°: {basic_file}")
            
            # ä¿å­˜å†å²æ•°æ®
            quotes_file = output_dir / 'daily_quotes.csv'
            combined_data.to_csv(quotes_file, index=False, encoding='utf-8')
            logger.success(f"âœ… å†å²æ•°æ®å·²ä¿å­˜åˆ°: {quotes_file}")
            
            logger.info(f"æˆåŠŸè·å– {success_count}/{total_count} åªè‚¡ç¥¨çš„æ•°æ®")
            logger.info(f"æ€»è®°å½•æ•°: {len(combined_data)}")
            
            return True
        else:
            logger.error("âŒ æœªè·å–åˆ°ä»»ä½•æ•°æ®")
            return False
        
    except Exception as e:
        logger.error(f"âŒ å¯¼å…¥è‚¡ç¥¨æ•°æ®å¤±è´¥: {e}")
        return False


def validate_imported_data():
    """éªŒè¯å¯¼å…¥çš„æ•°æ®"""
    logger.info("ğŸ” éªŒè¯å¯¼å…¥çš„æ•°æ®")
    
    try:
        data_dir = project_root / 'data' / 'production'
        
        # æ£€æŸ¥è‚¡ç¥¨åŸºç¡€ä¿¡æ¯
        basic_file = data_dir / 'stock_basic.csv'
        if basic_file.exists():
            basic_data = pd.read_csv(basic_file)
            logger.success(f"âœ… è‚¡ç¥¨åŸºç¡€ä¿¡æ¯: {len(basic_data)} æ¡è®°å½•")
            
            # æ˜¾ç¤ºå¸‚åœºåˆ†å¸ƒ
            if 'market' in basic_data.columns:
                market_dist = basic_data['market'].value_counts()
                logger.info("å¸‚åœºåˆ†å¸ƒ:")
                for market, count in market_dist.items():
                    logger.info(f"  {market}: {count} åª")
        else:
            logger.warning("âš ï¸ æœªæ‰¾åˆ°è‚¡ç¥¨åŸºç¡€ä¿¡æ¯æ–‡ä»¶")
        
        # æ£€æŸ¥å†å²æ•°æ®
        quotes_file = data_dir / 'daily_quotes.csv'
        if quotes_file.exists():
            quotes_data = pd.read_csv(quotes_file)
            logger.success(f"âœ… å†å²è¡Œæƒ…æ•°æ®: {len(quotes_data)} æ¡è®°å½•")
            
            # æ•°æ®ç»Ÿè®¡
            if not quotes_data.empty:
                unique_stocks = quotes_data['symbol'].nunique() if 'symbol' in quotes_data.columns else 0
                logger.info(f"æ¶µç›–è‚¡ç¥¨æ•°: {unique_stocks}")
                
                if 'date' in quotes_data.columns:
                    date_range = f"{quotes_data['date'].min()} åˆ° {quotes_data['date'].max()}"
                    logger.info(f"æ—¥æœŸèŒƒå›´: {date_range}")
                
                # æ˜¾ç¤ºæ•°æ®æ ·ä¾‹
                logger.info("æ•°æ®æ ·ä¾‹:")
                print(quotes_data.head().to_string())
                
                # æ•°æ®è´¨é‡æ£€æŸ¥
                if 'close' in quotes_data.columns:
                    null_count = quotes_data['close'].isnull().sum()
                    logger.info(f"æ”¶ç›˜ä»·ç¼ºå¤±å€¼: {null_count}")
                    
                    if null_count == 0:
                        logger.success("âœ… æ•°æ®è´¨é‡è‰¯å¥½ï¼Œæ— ç¼ºå¤±å€¼")
                    else:
                        logger.warning(f"âš ï¸ å‘ç° {null_count} ä¸ªç¼ºå¤±å€¼")
        else:
            logger.warning("âš ï¸ æœªæ‰¾åˆ°å†å²è¡Œæƒ…æ•°æ®æ–‡ä»¶")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ æ•°æ®éªŒè¯å¤±è´¥: {e}")
        return False


def generate_summary_report():
    """ç”Ÿæˆæ€»ç»“æŠ¥å‘Š"""
    logger.info("ğŸ“Š ç”Ÿæˆæ€»ç»“æŠ¥å‘Š")
    
    try:
        data_dir = project_root / 'data' / 'production'
        
        report = []
        report.append("=" * 80)
        report.append("Alpha Vantageç”Ÿäº§æ•°æ®å¯¼å…¥æŠ¥å‘Š")
        report.append("=" * 80)
        report.append(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report.append("")
        
        # æ£€æŸ¥æ•°æ®æ–‡ä»¶
        basic_file = data_dir / 'stock_basic.csv'
        quotes_file = data_dir / 'daily_quotes.csv'
        
        if basic_file.exists():
            basic_data = pd.read_csv(basic_file)
            report.append(f"ğŸ“‹ è‚¡ç¥¨åŸºç¡€ä¿¡æ¯: {len(basic_data)} åªè‚¡ç¥¨")
            
            if 'market' in basic_data.columns:
                market_dist = basic_data['market'].value_counts()
                for market, count in market_dist.items():
                    report.append(f"   - {market}: {count} åª")
        
        if quotes_file.exists():
            quotes_data = pd.read_csv(quotes_file)
            report.append(f"ğŸ“ˆ å†å²è¡Œæƒ…æ•°æ®: {len(quotes_data)} æ¡è®°å½•")
            
            if not quotes_data.empty:
                unique_stocks = quotes_data['symbol'].nunique() if 'symbol' in quotes_data.columns else 0
                report.append(f"   - æ¶µç›–è‚¡ç¥¨: {unique_stocks} åª")
                
                if 'date' in quotes_data.columns:
                    date_range = f"{quotes_data['date'].min()} åˆ° {quotes_data['date'].max()}"
                    report.append(f"   - æ—¥æœŸèŒƒå›´: {date_range}")
        
        report.append("")
        report.append("ğŸ”§ æ•°æ®æºé…ç½®:")
        report.append(f"   - Alpha Vantage Key: {ALPHA_VANTAGE_API_KEY[:10]}...")
        report.append("   - æ•°æ®ç±»å‹: ç¾è‚¡å’Œä¸­æ¦‚è‚¡")
        report.append("")
        report.append("ğŸ“ è¯´æ˜:")
        report.append("   - ç”±äºAllTickè¿æ¥é—®é¢˜ï¼Œä½¿ç”¨Alpha Vantageä½œä¸ºæ•°æ®æº")
        report.append("   - åŒ…å«ä¸»è¦çš„ä¸­æ¦‚è‚¡å’Œç¾è‚¡æ•°æ®")
        report.append("   - æ•°æ®è´¨é‡ç»è¿‡éªŒè¯")
        report.append("")
        report.append("ğŸš€ ä¸‹ä¸€æ­¥å»ºè®®:")
        report.append("   1. éªŒè¯æ•°æ®å®Œæ•´æ€§")
        report.append("   2. è¿è¡ŒæŠ€æœ¯åˆ†æ")
        report.append("   3. é…ç½®å®šæœŸæ•°æ®æ›´æ–°")
        report.append("=" * 80)
        
        # ä¿å­˜æŠ¥å‘Š
        report_content = "\n".join(report)
        
        # è¾“å‡ºåˆ°æ§åˆ¶å°
        print("\n" + report_content)
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        logs_dir = project_root / 'logs' / 'production'
        logs_dir.mkdir(parents=True, exist_ok=True)
        
        report_file = logs_dir / f'alpha_vantage_import_report_{timestamp}.txt'
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        logger.success(f"âœ… æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
        return True
        
    except Exception as e:
        logger.error(f"âŒ ç”ŸæˆæŠ¥å‘Šå¤±è´¥: {e}")
        return False


def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸš€ Alpha Vantageç”Ÿäº§æ•°æ®å¯¼å…¥")
    logger.info("=" * 80)
    
    logger.info("é…ç½®ä¿¡æ¯:")
    logger.info(f"  Alpha Vantage Key: {ALPHA_VANTAGE_API_KEY[:10]}...")
    logger.info("  æ•°æ®ç±»å‹: ç¾è‚¡å’Œä¸­æ¦‚è‚¡")
    logger.info("  è¯·æ±‚é™åˆ¶: æ¯åˆ†é’Ÿ5æ¬¡")
    
    # æ‰§è¡Œå¯¼å…¥æ­¥éª¤
    steps = [
        ("è®¾ç½®Alpha Vantageæ•°æ®æº", setup_alpha_vantage),
        ("åˆ›å»ºè‚¡ç¥¨åˆ—è¡¨", create_sample_stock_list),
        ("å¯¼å…¥è‚¡ç¥¨æ•°æ®", None),  # éœ€è¦å‚æ•°
        ("éªŒè¯å¯¼å…¥æ•°æ®", validate_imported_data),
        ("ç”Ÿæˆæ€»ç»“æŠ¥å‘Š", generate_summary_report)
    ]
    
    alpha_source = None
    stock_list = pd.DataFrame()
    
    try:
        # 1. è®¾ç½®æ•°æ®æº
        logger.info("\nğŸ¯ æ­¥éª¤1: è®¾ç½®Alpha Vantageæ•°æ®æº")
        alpha_source = setup_alpha_vantage()
        if not alpha_source:
            logger.error("âŒ æ•°æ®æºè®¾ç½®å¤±è´¥ï¼Œæ— æ³•ç»§ç»­")
            return False
        
        # 2. åˆ›å»ºè‚¡ç¥¨åˆ—è¡¨
        logger.info("\nğŸ¯ æ­¥éª¤2: åˆ›å»ºè‚¡ç¥¨åˆ—è¡¨")
        stock_list = create_sample_stock_list()
        if stock_list.empty:
            logger.error("âŒ è‚¡ç¥¨åˆ—è¡¨åˆ›å»ºå¤±è´¥ï¼Œæ— æ³•ç»§ç»­")
            return False
        
        # 3. å¯¼å…¥è‚¡ç¥¨æ•°æ®
        logger.info("\nğŸ¯ æ­¥éª¤3: å¯¼å…¥è‚¡ç¥¨æ•°æ®")
        if not import_stock_data(alpha_source, stock_list):
            logger.error("âŒ å¯¼å…¥è‚¡ç¥¨æ•°æ®å¤±è´¥")
            return False
        
        # 4. éªŒè¯æ•°æ®
        logger.info("\nğŸ¯ æ­¥éª¤4: éªŒè¯å¯¼å…¥æ•°æ®")
        if not validate_imported_data():
            logger.warning("âš ï¸ æ•°æ®éªŒè¯å¤±è´¥")
        
        # 5. ç”ŸæˆæŠ¥å‘Š
        logger.info("\nğŸ¯ æ­¥éª¤5: ç”Ÿæˆæ€»ç»“æŠ¥å‘Š")
        if not generate_summary_report():
            logger.warning("âš ï¸ æŠ¥å‘Šç”Ÿæˆå¤±è´¥")
        
        logger.success("ğŸ‰ Alpha Vantageç”Ÿäº§æ•°æ®å¯¼å…¥å®Œæˆï¼")
        return True
        
    except Exception as e:
        logger.error(f"âŒ å¯¼å…¥è¿‡ç¨‹å¼‚å¸¸: {e}")
        return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
